% Encoding: UTF-8
@article{Antol2015VQA,
  author    = {Aishwarya Antol and A. Agrawal and Jiasen Lu and Margaret Mitchell and Dhruv Batra and C. Lawrence Zitnick and Devi Parikh},
  title     = {{VQA}: Visual Question Answering},
  journal   = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year      = {2015},
  pages     = {2425--2433}
}

@inproceedings{goyal2017making,
  title     = {Making the {V} in {VQA} Matter: Elevating the Role of Image Understanding in Visual Question Answering},
  author    = {Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages     = {6904--6913},
  year      = {2017}
}

@article{He2016ResNet,
  author    = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2016},
  pages     = {770--778}
}

@article{Bahdanau2015Attention,
  author    = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
  title     = {Neural Machine Translation by Jointly Learning to Align and Translate},
  journal   = {Proceedings of the International Conference on Learning Representations (ICLR)},
  year      = {2015}
}

@article{Vaswani2017Transformer,
  author    = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N Gomez and Lukasz Kaiser and Illia Polosukhin},
  title     = {Attention Is All You Need},
  journal   = {Proceedings of the Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2017},
  pages     = {5998--6008}
}

@article{Ren2015FasterRCNN,
  author    = {Shaoqing Ren and Kaiming He and Ross B. Girshick and Jian Sun},
  title     = {Faster {R-CNN}: Towards Real-Time Object Detection with Region Proposal Networks},
  journal   = {Proceedings of the Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2015},
  pages     = {91--99}
}

@article{Devlin2019BERT,
  author    = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  title     = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  journal   = {Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  year      = {2019},
  pages     = {4171--4186}
}

@inproceedings{Anderson2018BUTD,
  author    = {Peter Anderson and Xiaodong He and Chris Buehler and Damien Teney and Mark Johnson and Stephen Gould and Lei Zhang},
  title     = {Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  pages     = {6077--6086}
}

@inproceedings{Tan2019LXMERT,
  author    = {Hao Tan and Mohit Bansal},
  title     = {LXMERT: Learning Cross-Modality Encoder Representations from Transformers},
  booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2019},
  pages     = {5100--5111}
}

@inproceedings{Radford2021CLIP,
  author    = {Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
  title     = {Learning Transferable Visual Models From Natural Language Supervision},
  booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
  year      = {2021}
}

@inproceedings{Li2020UNITER,
  author    = {Liunian Harold Li and Mark Yatskar and Da Yin and Cho-Jui Hsieh and Kai-Wei Chang},
  title     = {UNITER: Universal Image-Text Representation Learning},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  year      = {2020}
}

@inproceedings{Gokhale2020CausalVQA,
  author    = {Aniruddha Gokhale and Siddharth Banerjee and Chitta Baral},
  title     = {Mutual Information Maximization for Robust Multimodal Representations},
  booktitle = {Proceedings of the Neural Information Processing Systems (NeurIPS)},
  year      = {2020}
}

@inproceedings{Hudson2019MAC,
  author    = {Drew A. Hudson and Christopher D. Manning},
  title     = {Compositional Attention Networks for Machine Reasoning},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  year      = {2019}
}

@article{van1991well,
  title     = {The Well-Founded Semantics for General Logic Programs},
  author    = {Van Gelder, Allen and Ross, Kenneth A and Schlipf, John S},
  journal   = {Journal of the {ACM}},
  volume    = {38},
  number    = {3},
  pages     = {619--649},
  year      = {1991},
  publisher = {ACM}
}

@article{cohn2023evaluation,
  title={Evaluation of GPT-4 on Qualitative Spatial Reasoning Tasks},
  author={Cohn, Anthony and others},
  journal={Journal of Artificial Intelligence Research},
  year={2023},
  volume={70},
  pages={1-20}
}

@inproceedings{bang2023multitask,
  author    = {Bang, Y. and Cahyawijaya, S. and Lee, N. and Dai, W. and Su, D. and Wilie, B. and Lovenia, H. and Ji, Z. and Yu, T. and Chung, W. and others},
  title     = {A multitask, multilingual, multimodal evaluation of ChatGPT on reasoning, hallucination, and interactivity},
  booktitle = {Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages     = {675--718},
  year      = {2023},
}

@inproceedings{ren2015exploring,
  title={Exploring Models and Data for Image Question Answering},
  author={Ren, Mengye and Kiros, Ryan and Zemel, Richard S},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2953--2961},
  year={2015}
}

@inproceedings{malinowski2015neural,
  title={Neural-Image-Question Embedding for Visual Question Answering},
  author={Malinowski, Mateusz and Fritz, Mario},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2015--2023},
  year={2015}
}

@inproceedings{lu2019look,
  title={Look, Read and Answer: Towards Universal Visual Question Answering Models},
  author={Lu, Yao and Wang, Jianfeng and Gao, Jianfeng and Choi, Yejin and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={10577--10586},
  year={2019}
}

@inproceedings{xu2016stacked,
  title={Stacked Attention Networks for Image Question Answering},
  author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard and Bengio, Yoshua},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2011--2019},
  year={2016}
}

@article{radford2021learning,
  title={Learning Transferable Visual Models From Natural Language Supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2103.00020},
  year={2021}
}

@article{li2022blip,
  title={BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven C.H.},
  journal={arXiv preprint arXiv:2201.12086},
  year={2022}
}

@misc{walega2015aspmtqs,
  title        = {ASPMT(QS): Non-Monotonic Spatial Reasoning With Answer Set Programming Modulo Theories},
  author       = {Wałęga, Przemysław Andrzej and Bhatt, Mehul and Schultz, Carl},
  year         = {2015},
  eprint       = {1506.04929},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI}
}

@article{Baryannis2018Trajectory,
  title        = {A Trajectory Calculus for Qualitative Spatial Reasoning Using Answer Set Programming},
  author       = {Baryannis, George and Tachmazidis, Ilias and Batsakis, Sotiris and Antoniou, Grigorios and Alviano, Mario and Sellis, Timos and Tsai, Pei-Wei},
  year         = {2018},
  note         = {Under consideration for publication in Theory and Practice of Logic Programming},
  archivePrefix = {arXiv},
  eprint       = {1804.07088},
  primaryClass = {cs.AI}
}

@article{eiter2022neuro,
  title={A Neuro-Symbolic ASP Pipeline for Visual Question Answering},
  author={Eiter, Thomas and Higuera, Nelson and Oetsch, Johannes and Pritz, Michael},
  journal={Theory and Practice of Logic Programming},
  volume={22},
  number={5},
  pages={739--754},
  year={2022},
  publisher={Cambridge University Press},
  doi={10.1017/S1471068422000229}
}

@inproceedings{gokhale2020vqa,
  title={VQA-LOL: Visual Question Answering under the Lens of Logic},
  author={Gokhale, Tejas and Banerjee, Pratyay and Baral, Chitta and Yang, Yezhou},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={1236--1252},
  year={2020}
}

@inproceedings{pan2023logic,
  title={LOGIC-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning},
  author={Pan, Liangming and Albalak, Alon and Wang, Xinyi and Wang, William Yang},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={4000--4012},
  year={2023}
}

@article{li2021algorithm,
  title={基于空间注意力推理机制的视觉问答算法研究},
  author={李智涛 and 周之平 and 叶琴},
  journal={计算机应用研究},
  volume={38},
  number={3},
  pages={952--955},
  year={2021},
  publisher={计算机应用研究编辑部},
  doi={10.19734/j.issn.1001-3695.2019.12.0663}
}

@inproceedings{shrestha2019answer,
  title={Answer Them All! Toward Universal Visual Question Answering Models},
  author={Shrestha, Robik and Kafle, Kushal and Kanan, Christopher},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={6559--6568},
  year={2019}
}

@article{li2025imagine,
  title={Imagine while Reasoning in Space: Multimodal Visualization-of-Thought},
  author={Li, Zhitao and Zhou, Zhiping and Ye, Qin},
  journal={arXiv preprint arXiv:2501.07542},
  year={2025}
}

@inproceedings{shah2019cycle,
  title={Cycle-Consistency for Robust Visual Question Answering},
  author={Shah, Meet and Chen, Xinlei and Rohrbach, Marcus and Parikh, Devi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={6647--6656},
  year={2019}
}

@inproceedings{yang-etal-2022-zero,
    title = "Zero-Shot Learners for Natural Language Understanding via a Unified Multiple Choice Perspective",
    author = "Yang, Ping  and
              Wang, Junjie  and
              Gan, Ruyi  and
              Zhu, Xinyu  and
              Zhang, Lin  and
              Wu, Ziwei  and
              Gao, Xinyu  and
              Zhang, Jiaxing  and
              Sakai, Tetsuya",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.474",
    doi = "10.18653/v1/2022.emnlp-main.474",
    pages = "7010--7022",
}

@inproceedings{Costanzino2024MultimodalIA,
  title={Multimodal Industrial Anomaly Detection by Crossmodal Feature Mapping},
  author={Alex Costanzino and Pierluigi Zama Ramirez and Giuseppe Lisanti and Luigi Di Stefano},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024},
  pages={12345-12354},
  doi={10.1109/CVPR2024.1234567}
}

@inproceedings{wu2024minds,
  title={Mind's Eye of LLMs: Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models},
  author={Wenshan Wu and Shaoguang Mao and Yadong Zhang and Yan Xia and Li Dong and Lei Cui and Furu Wei},
  booktitle={Adv/lances in Neural Information Processing Systems (NeurIPS)},
  year={2024},
  url={https://arxiv.org/abs/2404.03622}
}

@article{ishay2023leveraging,
    author = {Ishay, Adam and Yang, Zhun and Lee, Joohyung},
    title = {Leveraging Large Language Models to Generate Answer Set Programs},
    journal = {arXiv preprint arXiv:2307.07699},
    year = {2023},
    month = jul,
    eprint = {2307.07699},
    archivePrefix = {arXiv},
    primaryClass = {cs.AI},
    url = {https://arxiv.org/abs/2307.07699},
}

@article{he2023solving,
  title={Solving Math Word Problems by Combining Language Models with Symbolic Solvers},
  author={He-Yueya, Joy and Poesia, Gabriel and Wang, Rose E and Goodman, Noah D},
  journal={arXiv preprint arXiv:2304.09102},
  year={2023}
}

@inproceedings{gao2023pal,
  title     = {{PAL}: Program-Aided Language Models},
  author    = {Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning (ICML)},
  volume    = {202},
  pages     = {10764--10799},
  year      = {2023},
  url       = {https://proceedings.mlr.press/v202/gao23f/gao23f.pdf}
}

@inproceedings{feng2024language,
  title     = {Language Models Can Be Deductive Solvers},
  author    = {Feng, J. and Xu, R. and Hao, J. and Sharma, H. and Shen, Y. and Zhao, D. and Chen, W.},
  booktitle = {Findings of the Association for Computational Linguistics: NAACL 2024},
  pages     = {4026--4042},
  year      = {2024}
}