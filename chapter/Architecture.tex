\chapter{RCNSP的设计与实现}
本章介绍规则自动补全的神经符号VQA框架（Rule Complement Neuro-Symbolic Pipeline, RCNSP），
下面分别从RCNSP设计方案、RCNSP核心技术及实现、实验分析三个方面进行详细阐述。
\section{RCNSP设计方案}
RCNSP框架的架构设计如图\ref{fig:pipeline}所示。框架的整体设计思路是：
在框架初始化阶段，规则蒸馏模块依据LLM中蕴含的大量知识生成ASP规则，进而获得较为完整的ASP知识库。
在框架运行阶段，视觉场景理解模块从输入的图像中抽取
物体所在区域、物体属性等信息，并以ASP形式进行表示。
另一方面，语义解析模块对输入的自然语言问题进行解析，
同样以ASP形式进行表示，并由规则修正模块对生成的ASP规则进行修正。
随后将ASP知识库、图像、问题、环境约束这四个方面的ASP规则统一输入ASP推理模块进行求解。如果对某个问题无法求解出正确答案，
规则蒸馏模块会尝试进行生成新规则，实现ASP知识库的动态更新。
最后，由于ASP推理模块输出的是ASP语句，
可读性较差，普通用户难以理解，因此需要求解结果翻译模块将其翻译为自然语言形式进行输出。
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/pipeline-crop.pdf}
    \caption{RCNSP架构图}
    \label{fig:pipeline}
\end{figure}
下面将分别对RCNSP中所涉及的各个模块展开介绍。
\begin{enumerate}[nosep]
\item \textbf{视觉场景理解模块}：
本模块的任务是从输入的积木世界图像中检测积木物体并提取其属性（颜色、形状、大小、材质）、位置以及相互之间的空间关系，并把
这些视觉信息转换为符号化的ASP事实（如\texttt{color(obj1,red)}、\texttt{shape(obj1, cube)}、\texttt{left(obj1,obj2)}等）。

技术方法上，本文使用GLIP作为目标检测模型，GLIP完成目标检测后，经空间位置提取、空间关系提取后，生成该图像对应使用ASP表示的场景。

现有的空间推理领域的神经符号框架\cite{wang2024DSPy}是面向纯文本空间推理数据集的，不支持图像输入，不能完成积木世界VQA任务，本文引入视觉场景理解模块，使RCNSP具备现有空间推理神经符号框架所不支持
的处理多模态输入的能力。
\item \textbf{语义解析模块}：
本模块的目标是将用户的自然语言问题转化为能够准确反映积木世界VQA问题且语法和语义均正确的ASP查询，以支持后续推理。
本模块的研究中的难点在于，如何在训练LLM生成ASP程序的相关数据集较少的情况下，指导LLM准确生成ASP程序。

技术方法上，本模块采用提示词优化的方法对LLMs进行优化，并引入DSPy作为提示管理的框架，
针对POVQAD中积木世界VQA的3类空间推理问题设计了共一系列提示词以训练LLMs准确生成对应的ASP程序，此外使用了本文第三章中
同时考察语法正确和语义正确两方面的自定义评价函数\texttt{ValidScore}，用以指导DSPy的 FewShotPromptOptimizer 优化器对提示词进行优化。

相较于通用的LLMs生成ASP程序的方法，本模块的方法更专注于POVQAD中3类空间推理问题的语言特性，
能够更准确高效地处理涉及物体属性和空间关系的问题，减少歧义解析的错误率。
\item \textbf{规则修正模块}：
本模块的任务是在通过语义解析模块得到ASP查询之后，进行多轮迭代检查与修正，确保ASP查询正确无误，可以顺利通过Clingo执行。
本模块研究中的难点在于，LLM在生成ASP规则时容易出错，且目前学术界和工业界很少有针对积木世界VQA相关的ASP程序进行修正的微调数据集，
难以采用微调的方法对生成ASP规则进行优化。

技术方法上，本文设计了多种提示模板，通过DSPy框架对LLM进行提示词优化，使模型在无需重新训练的情况下，自动学习如何更有效地修正 ASP 程序，
同时提示词优化降低了对大量高质量标注数据的需求，很大程度上解决了本模块研究中的难题。

本方法相比已有工作的创新点在于，已有工作中的ASP代码修正依赖于预先定义的ASP错误类型和修正策略。而本方法通过引入Clingo的执行反馈提示，
指导提示词的动态变化，在保持模型参数不变的前提下，显著提高了ASP程序的可执行性和准确率。
\item \textbf{规则蒸馏模块}：
本模块旨在从LLMs中提取简洁且准确的ASP规则，用于积木世界的推理任务。
具体应用主要包括两方面：一是在RCNSP初始化阶段，利用“LLMs基于海量语料预训练，包含
丰富的知识”这一特性，将LLMs中蕴含的知识转换为可执行、可解释的ASP规则的，用于完善初始ASP知识库。
二是在RCNSP运行阶段，当出现对某个问题无法求解出正确答案的情况时，
规则蒸馏模块会尝试进行生成新规则，实现ASP知识库的动态更新。

本模块研究的难点在于，在RCNSP初始化阶段使用积木世界VQA数据集进行蒸馏的过程中，当样本的数量过多时，进行全量蒸馏
可能会耗时过长，同时也能会引入一些对解决积木世界VQA问题无关的冗余知识。这些冗余知识在每次ASP推理时，都要输入到Clingo中，
当RCNSP处理用户VQA请求数量逐步增加时，因冗余知识而导致的累计性能损耗也将逐步增大。

技术方法上，本模块通过构建初始ASP知识库，并以本文构建的积木世界数据集POVQ\-AD为样本进行蒸馏，生成积木世界空间推理所需的ASP规则并完善ASP知识库。
另外在RCNSP运行过程中，当出现知识不足，无法求解的情况时，规则蒸馏模块将会引导LLM生成新的ASP规则以补充ASP知识库。
同时，本模块在蒸馏过程中采用了样例选择策略，减少无关数据的干扰，避免全量蒸馏，实现了蒸馏性能优化，解决了本模块研究中的难点。

与已有工作中传统的模型压缩式蒸馏不同，本方法强调将LLM中“隐式的知识”显式地提取为ASP规则，因而规则蒸馏的本质是将大语言模型中蕴含的知识，转换为可执行、可解释的逻辑规则，用于扩展已有的推理系统。
\item \textbf{ASP推理模块}：
本模块的功能是：根据输入图像的ASP表示、ASP知识库中的ASP规则、经过修正后自然语言问题对应的ASP查询以及图像对应的环境约束，
共同输入到Clingo，生成答案集。
通过环境约束、图像以及ASP知识库中包含的积木世界空间推理的相关知识，Clingo可以对问题进行回答。
\item \textbf{求解结果翻译模块}：
本模块的功能是：将ASP推理模块输出的答案集，经LLM处理将其转换为自然语言形式的答案。由于Clingo求解后得到的为ASP谓词，对普通用户
并不友好，难以直接理解求解结果，故采用LLM对其进行翻译，转换成对普通用户更为友好的答案。
\end{enumerate}
\section{RCNSP核心技术及实现}
\subsection{视觉场景理解}
本节主要围绕视觉场景理解的流程展开详细阐述，具体包括目标检测、空间位置提取、空间关系提取以及场景生成这四个环节。
最后，给出一个完整的视觉场景理解演示案例，并讨论在实现过程中遇到的关键技术挑战及相应解决方案。

关于目标检测的技术选型，本文采用了GLIP模型作为目标检测的核心工具，其主要优势体现在：
\begin{enumerate}[nosep] 
\item \textbf{语言-视觉预训练能力：}GLIP在大规模图文对数据上进行预训练，能够根据自然语言描述（例如“红色立方体”）直接定位图像中的对应物体，从而实现图像内容与问题描述的高效对齐； 
\item \textbf{高效性与鲁棒性：}模型在处理多样化场景时具有较高的检测准确率，适合构造后续依赖视觉信息的场景图。 
\end{enumerate}

目标检测的具体实现流程如下：
\begin{enumerate}[nosep] 
\item \textbf{图像预处理：}将原始图像调整至GLIP模型要求的输入分辨率（例如800$\times$600像素），
以保证检测精度； 
\item \textbf{文本提示构造：}根据POVQAD数据集，设计一组覆盖目标类别及属性的自然语言提示。
本文选取的提示短语包括描述物体大小（如“大物体”、“小物体”）以及颜色与形状组合（如“红色立方体”、“蓝色球体”、“绿色圆柱体”等）； 
\item \textbf{目标检测与属性解析：}将图像和文本提示输入GLIP，获得每个检测物体的边界框和类别标签。随后对类别标签进行解析，将复合描述（如“红色立方体”）拆解为单独属性（color=red, shape=cube）。同时，通过计算边界框面积（$(x_2 - x_1)\times(y_2 - y_1)$），结合预设阈值进一步推断物体的大小属性。 
\end{enumerate}

在完成目标检测后，进行的是空间位置提取。空间位置提取的目的是为每个物体确定其精确的空间位置，这对于后续空间关系的推理至关重要。
本文采用以下两种方式提取物体位置信息：
\begin{enumerate}[nosep]
\item \textbf{二维中心点计算}：利用目标检测得到的边界框信息，计算物体在图像平面内的中心点坐标。公式如下：
$$x_c = \frac{x_1+x_2}{2}, y_c = \frac{y_1 + y_2}{2}$$
该中心点坐标用于描述物体在二维图像中的位置，其中$(x_1,y_1)$和$(x_2,y_2)$分别为边界框的左上顶点坐标和右下顶点坐标。
\item \textbf{三维位置信息获取}：图像同时包含深度信息，则可直接从深度图中提取物体的z值，从而获得物体在三维空间中的位置，
表示为$(x, y, z)$。
\end{enumerate}
提取出的位置信息将以ASP事实的形式进行存储，例如：position(obj1, x1c, y1c, z1) 表示物体1的中心点位置。

在空间位置提取之后，需要进行空间关系提取。空间关系提取是实现复杂场景理解与多步逻辑推理的关键。本文从以下几个角度对空间关系进行提取：
\begin{enumerate}[nosep]
\item \textbf{二维空间关系：}基于物体的中心点坐标计算物体之间的相对位置。例如： 
    \begin{itemize}[leftmargin=2em] 
        \item 若物体A的$x_c$小于物体B的$x_c$，则判定A位于B的左侧，表示为\texttt{left(objA, objB)}； 
        \item 类似地，通过比较$y_c$坐标可判定上下关系（例如，若物体A的$y_c$小于B，则A在B之上，记作\texttt{above(objA, objB)}）。 
    \end{itemize} 
\item \textbf{三维空间关系：}利用深度信息，对物体间的前后关系进行判断。
例如，若物体A的z值小于物体B的z值，则判定A位于B的前面，记作\texttt{front(objA, objB)}。 
\end{enumerate}
所有提取到的空间关系均转换为ASP事实，如：
left(obj1, obj2) 表示物体1在物体2的左边，front(obj1, obj2) 表示物体1在物体2的前面。

场景图是将目标检测、空间位置与空间关系综合融合成的统一结构化表示，使用ASP作为表示形式，其主要构成如下： 
\begin{enumerate}[nosep] 
    \item \textbf{节点表示：}每个节点对应图像中的一个物体，并附有相应的属性（如color, shape, size, material）以及位置信息； 
    \item \textbf{边的构建：}节点之间的边用于表示物体间的空间关系，如left、front等。 
\end{enumerate}

在构建过程中，首先为每个检测到的物体创建一个节点，并记录其属性及位置；随后，依据前述空间关系，将相应的有向边添加到图中。最终，整个场景图将被转化为ASP事实，以支持后续符号推理任务。

为便于理解整个视觉场景理解的工作流程，下面给出一个具体示例。假设输入图像包含如下场景： 
\begin{enumerate}[nosep] 
    \item 一个红色大立方体位于图像左侧； 
    \item 一个蓝色小球体位于图像右侧，且位于红色立方体的前方。 
\end{enumerate}

经过GLIP目标检测，得到如下检测结果： 
\begin{itemize}[itemsep=0pt,parsep=0pt] 
    \item 物体1：类别为“红色立方体”，边界框为(50, 100, 150, 200)； 
    \item 物体2：类别为“蓝色球体”，边界框为(250, 50, 350, 150)。 
\end{itemize}

进一步计算得到： 
\begin{itemize}[itemsep=0pt,parsep=0pt] 
    \item 物体1的中心点坐标为$(100,150)$； 
    \item 物体2的中心点坐标为$(300,100)$。 
\end{itemize}

假设深度信息显示：物体1的z值为50，物体2的z值为75，则可提取以下空间关系： 
\begin{itemize}[itemsep=0pt,parsep=0pt] 
    \item \texttt{left(obj1, obj2)}（因为100 $<$ 300）； 
    \item \texttt{above(obj2, obj1)}（因为100 $<$ 150）； 
    \item \texttt{front(obj2, obj1)}（因为75 $>$ 50，在三维空间中深度值较大的物体更靠后，需根据具体定义调整）。 
\end{itemize}

最终生成的ASP事实示例如下： 
\begin{lstlisting}[language=Prolog] 
color(obj1, red). 
shape(obj1, cube). 
size(obj1, large). 
position(obj1, 100, 150, 50).

color(obj2, blue). 
shape(obj2, sphere). 
size(obj2, small). 
position(obj2, 300, 100, 75).

left(obj1, obj2). 
above(obj2, obj1). 
front(obj2, obj1). 
\end{lstlisting}
\subsection{语义解析}
为了让LLM更准确地生成积木世界VQA任务中的ASP程序，本文在此对通用LLM进行提示词优化，
并且引入DSPy作为提示管理与语义生成框架，以构建结构化、模块化、可优化的语义解析流程。
本节按照任务定义、提示词设计、提示词优化、输出的顺序进行介绍。
\begin{enumerate}[nosep]
\item \textbf{任务定义}：DSPy是一个面向语言任务的程序性提示框架，能够在具备结构化的输入输出约束的前提下，
调用LLM完成特定子任务。在语义解析模块中，将“问题$\rightarrow$ASP程序”建模为一个标准的DSPy模块，
定义其输入为英文问题，输出为符合ASP语法的逻辑规则字符串。

在实现上，本文通过DSPy的\texttt{Signature}进行任务定义，明确了模块的目标，即
根据输入问句生成问题所对应的ASP逻辑表示。
\begin{lstlisting}
class ParseQuestionToASP(Signature):
    question = DSPy.InputField(desc="问题")
    asp_code = DSPy.OutputField(desc="ASP程序片段")
\end{lstlisting}
\item \textbf{提示词设计}：本文对第三章中构建的积木世界VQA数据集POVQAD的问题进行分析，对3种空间推理问题分别设计提示词。
考虑到POVQAD中问题表述的多样性，每种问题的提示模板均有多种形式。以下对3种问题分别展示一种提示词。所有提示词在附录\ref{appendix:semantics-parsing-prompts}中予以展示。
\begin{enumerate}[nosep]
\item \textbf{位置类问题}：问题对物体所在的位置进行提问或者对参照物的某个随机选中的方向上的物体的属性进行提问。
\begin{lstlisting}
问题：What is the color of the object that is above the large blue metal cube?
ASP程序：
query(Q) :-
    has_property(X, color, Q),above(X, Y),
    has_property(Y, size, large),has_property(Y, color, blue),
    has_property(Y, material, metal),has_property(Y, shape, cube),
    X != Y.
\end{lstlisting}
\item \textbf{位置关系类问题}：询问两物体或者更多物体之间的位置关系。
\begin{lstlisting}
问题：Is the green rubber sphere in front of the red metal cube?
ASP程序：
query(front(X, Y)) :-
    has_property(X, color, green),has_property(X, material, rubber),
    has_property(X, shape, sphere),has_property(Y, color, red),
    has_property(Y, material, metal),has_property(Y, shape, cube),
    X != Y.
\end{lstlisting}
\item \textbf{位置有关的计数类问题}：以物体为中心，对其某个或多个方向上满足特定要求的物体的数量进行计数。
\begin{lstlisting}
问题：How many small blue spheres are to the left of the red cube?
ASP程序：
query(count(X)) :-
    has_property(X, size, small),has_property(X, color, blue),
    has_property(X, shape, sphere),has_property(Y, color, red),
    has_property(Y, shape, cube),left(X, Y),X != Y.
\end{lstlisting}
\end{enumerate}

最终在\texttt{PromptModule}中设定统一提示模板，引导模型按照所示结构生成ASP程序。
\item \textbf{提示词优化}：为进一步提升提示学习的效果，本文引入验证集驱动的提示优化策略。本文随机选取POVQAD中部分问题及对应ASP表示，组成验证集，通过
语法准确率和语义准确率，对少样本示例顺序与提示模板进行自动调整。

此处采用DSPy提供的 FewShotPromptOptimizer 优化器，以ASP程序的语法正确率和语义正确率作为评价指标，训练优化提示内容：
\begin{lstlisting}
optimizer = FewShotPromptOptimizer(devset=dev_questions, metric=asp_valid_score)
optimized_parse_module = optimizer(parse_module)
\end{lstlisting}

DSPy提供了FewShotPromptOptimizer、ReActPromptOptimizer、ChainOfThoughtOptimizer等多种提示词优化器，本文在此处选用
FewShotPromptOptimizer主要基于以下几点考量：
\begin{enumerate}[nosep]
\item 积木世界VQA的语义解析任务，也即根据自然语言问题生成其对应的ASP查询程序，本质上“结构化映射”而非“多轮推理”，属于结构预测任务。
并不需要模型生成复杂的思维链条或搜索多个中间步骤，因此并不适合使用 ReActPromptOptimizer 或 ChainOfThoughtOptimizer 这类用于逐步思考与规划的优化器。
\item 在任务定义中，已经确定了清晰的输入输出结构，并且已经根据POVQAD中3类问题的特点构造了“问题-ASP程序”示例对。
FewShotPromptOptimizer 正是专门用于自动选择、排列、剪枝、重组这些示例对以提升提示效果的优化器，它能用验证集度量“哪组少样本示例组合效果最好”，无需引入额外监督。
\item FewShotPromptOptimizer完全不依赖 LLM 微调，也不需要多轮推理轨迹采集，训练稳定、开销小，适合结构化语言映射任务。
此外，相比 ReActPromptOptimizer，它不需要考虑中间推理路径，因此构造门槛更低。
\item FewShotPromptOptimizer 的核心机制是“提供格式完好的示例”，它能有效帮助LLM学到一致的生成模式，
而 ReActPromptOptimizer 或 ChainOfThoughtOptimizer 更强调思维路径，反而容易引入不必要的多样性或碎片化表达，进而
可能导致输出的ASP程序在格式、句法上出现错误。
\end{enumerate}

上述优化器中的参数\texttt{asp\_valid\_score}为自定义评价函数，用于判断LLM输出的ASP程序是否满足语法正确和语义正确。
该函数的定义同\ref{self-define-func}节中定义的自定义评价函数相同，也是通过语法正确和语义正确来判断，故此处不再赘述。
\item \textbf{输出}：经过优化后的提示模块，能够将输入的问题稳定地转换为标准ASP规则，输出示例如下：
\begin{lstlisting}
query(Q):-hasProperty(X,size,Q),hasProperty(X,color,brown).
\end{lstlisting}

生成的程序将作为RCNSP神经符号推理流程中的一部分，结合视觉场景理解模块生成的ASP事实以及ASP知识库中的规则，共同组成可执行程序，
并提交至Clingo求解器进行推理。
\end{enumerate}
\subsection{规则修正}
整个规则修正的流程图如\ref{figure:rule-fix}所示，工作流程可分为以下几步：
\begin{enumerate}[nosep]
\item 使用Clingo求解器对语义解析模块生成的ASP程序尝试执行。
\item 如果执行成功，没有提示错误，则无需进行进一步修正，直接将ASP程序流转到框架的下一模块。
\item 如果执行失败，则将错误的ASP程序和Clingo求解器提示的错误信息，一起输入LLM，由LLM尝试进行修正。
\item 将修正后的ASP程序再次输入到Clingo求解器中，尝试执行。如此循环最多3次，最终输出经过优化后的ASP程序，流转到框架的下一模块。
\end{enumerate}
\begin{figure}[h]
\centering
\includegraphics[scale=1.5]{figures/rule-fix-crop.pdf}
\caption{规则修正流程图}
\label{figure:rule-fix}
\end{figure}

下面将按照任务定义、提示词设计、提示词优化的顺序对规则修正模块展开介绍。
\begin{enumerate}[nosep]
\item \textbf{任务定义}：
规则修正的任务为：输入错误的ASP程序和Clingo错误的类型、具体提示信息，输出一个修正后的ASP程序。对应使用DSPy的Signature结构表示如下：
\begin{lstlisting}[language=python]
class FixASPProgram(Signature):
    error_code = DSPy.InputField(desc="Clingo返回的错误的ASP代码")
    error_type = DSPy.InputField(desc="Clingo报错的类型")
    error_message = DSPy.InputField(desc="Clingo报错的提示信息")
    corrected_code = DSPy.OutputField(desc="修正后的ASP程序")
\end{lstlisting}
\item \textbf{提示词设计}：
针对常见的ASP程序错误类型，本文设计了多组提示模板，如表\ref{tab:asp-fix-templates}所示。
每类错误对应一个标准化任务描述、错误信息段、以及格式规范的修复输出示例。如下为语法错误的提示示例，其它类型的提示词在附录\ref{appendix:rule-fix}中展示，此处不再赘述。
\begin{table}[H]
\centering
\caption{常见ASP程序错误类型与修正策略}
\begin{tabular}{|l|p{5.5cm}|p{5.5cm}|}
\hline
\textbf{错误类型} & \textbf{描述} & \textbf{修正策略} \\
\hline
语法错误 & 缺少句点、括号不匹配、非法符号等 & 补齐缺失符号或调整语法结构 \\
\hline
基础化错误 & 不安全变量未绑定 & 增加正文字面量以绑定变量 \\
\hline
逻辑错误 & 冲突规则或条件导致无解 & 注释掉冲突规则或添加前提条件 \\
\hline
谓词未定义 & 使用未声明的谓词或拼写错误 & 添加定义或修正谓词名称 \\
\hline
负循环依赖 & 循环依赖中含有否定项 & 拆解规则结构，引入新谓词或添加约束 \\
\hline
\end{tabular}
\label{tab:asp-fix-templates}
\end{table}
\begin{lstlisting}
任务描述：请根据提供的 ASP 程序和 Clingo 错误信息，对程序进行修正。
错误类型：语法错误（Syntax Error）—— 缺少句点。
Clingo错误信息：
<stdin>:3:1: error: syntax error, unexpected IDENTIFIER, expecting '.' or ':
  node(b)
错误程序：
node(a).
node(b)  % <- 缺少句号
edge(a,b).
修正后程序：
node(a).
node(b).
edge(a,b).
\end{lstlisting}
使用DSPy的\texttt{Example}对这一类少样本结构进行封装，结构如下所示，以供后续提示词优化中的优化器使用。
\begin{lstlisting}[language=python]
from DSPy import example

examples = [
    Example(
        inputs={
            "error_code": "node(a). node(b) edge(a,b). path(X,Y) :- edge(X,Y). path(X,Z) :- edge(X,Y), path(Y,Z).",
            "error_description": "Missing period at the end of rule.",
            "error_type": "<stdin>:3:1: error: syntax error, unexpected IDENTIFIER, expecting '.' or ':node(b)"
        },
        outputs={
            "corrected_code": "node(a). node(b) edge(a,b). path(X,Y) :- edge(X,Y). path(X,Z) :- edge(X,Y), path(Y,Z)."
        }
    ),
    ...
]
\end{lstlisting}
\item \textbf{提示词优化}：
在构建示例后，使用DSPy的 FewShotPromptOptimizer 对提示词结构进行自动优化：
\begin{lstlisting}[language=python]
from DSPy.optimize import FewShotPromptOptimizer

optimizer = FewShotPromptOptimizer(devset=validation_set, metric=syntax_semantic_match_score)
optimized_module = optimizer(FixASPProgram)
\end{lstlisting}
此处选择FewShotPromptOptimizer的理由与“语义解析”模块中选择FewShotPromptOptimizer的理由类似，
该优化器会对 少样本 示例进行排序、筛选与重组合，并根据验证集的“语法/语义正确率”反馈来自动调整提示组合，从而获得最优提示配置。

此处的评价指标与“语义解析”模块中同样，选择语法正确率与语义正确率，自定义评价函数\texttt{syntax\_semantic\_match\_score}的定义
自然同样与“语义解析”模块中的自定义评价函数类似，此处不再赘述。

这种方式相比手工设计提示更为稳定、系统性强，且不依赖参数更新，能更好适应不同LLM（如GPT-4、LLaMA3等） 。
\end{enumerate}
\subsection{规则蒸馏}
规则蒸馏的流程如图\ref{distill-process}所示，分为RCNSP运行前构建ASP知识库的规则蒸馏，以及处理VQA请求时补充ASP知识库的规则蒸馏。
本节将依次对这两种情形的规则蒸馏进行介绍，并介绍蒸馏过程中的性能优化方法。
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.9]{figures/distillation.drawio-crop.pdf}
    \caption{规则蒸馏流程图}
    \label{distill-process}
\end{figure}
\subsubsection{RCNSP运行前构建ASP知识库的规则蒸馏}
RCNSP运行前构建ASP知识库的规则蒸馏的目的是：在RCNSP运行前，利用本文构建的积木世界VQA数据集POVQAD中的问题与答案，引导LLM
自动生成用于解决部分可见积木世界场景下的空间推理VQA问题的ASP规则，并补充到ASP知识库中，以供后续RCNSP运行时解决用户问题时使用。

初始ASP知识库是规则蒸馏的起点，其中包含了一些人工编写的、部分完备的规则集合，用于支持VQA系统在一定程度上进行最基本的逻辑推理。
执行VQA任务的过程中，问题的多样性和复杂性导致很难一次性将解决问题所需的所有知识都填充到ASP知识库中。
因此，需要构建一个初始ASP知识库，后续再不断在解决问题的过程中总结、归纳经验，对其拓展和完善。

初始ASP知识库的构建遵循“最小可运行”的原则，即在保证系统能够正确回答部分问题实例的前提下，
仅包含最基本的一些ASP规则，这些规则全部展示在附录\ref{appendix:initial-theory}中，用于预提示环节。

初始ASP知识库中通常包含以下几个方面的规则：
\begin{enumerate}[nosep]
\item 基本推理操作规则，包括属性过滤（如\texttt{filter\_color}、\texttt{filter\_shape}）、
对象选择（\texttt{select}）、合取与析取（\texttt{and}、\texttt{or}）、数量计算（\texttt{count}）、
布尔值判断（\texttt{exist}、\texttt{verify\_property}）等等。例如：
\begin{lstlisting}
state(TO,ID) :- scene(TO), object(ID).  % 初始状态：每个object都在场景中
state(TO,ID) :- select(TO, TI, CLASS), state(TI, ID), has_property(ID, class).
bool(TO,yes) :- or(TO, TI0, TI1), bool(TI0,yes).
ans(V) :- end(TO), property(TO,V).
:- not ans(_).  % 强制必须产生答案
\end{lstlisting}
以上这些规则都使用变量表达，而非常量，以保持泛化能力。
\item 根据数据集中常见问题需求构建规则。POVQAD中，问题均围绕物体的空间位置关系或者所在区域等进行提问。
可以根据数据集中的问题类型，构建一些常见的规则，例如针对提问目标物体的所在区域的问题，可能要用到物体的
其它属性、相对方向关系等信息来间接推理，可以构建\texttt{filter\_shape}、\texttt{fiter\_region}、
\texttt{filter\_material}、\texttt{filter\_size}、\texttt{filter\_relation}等规则，
其作用是根据物体的形状、区域、材质、大小、等属性以及相对位置关系进行过滤，从而帮助找出目标物体。
\end{enumerate}

通过构建初始ASP知识库，一方面保证了系统可以运行并进行基本验证，另一方面也为LLM提供了清晰、结构化的理论框架，
使其可以基于已有规则进行合理补全。

在初始ASP知识库构建完成后，使用本文构建的POVQAD中的训练集来引导LLM进行规则蒸馏，利用LLM自身知识生成扩展规则以补充初始ASP知识库。
对POVQAD训练集中所有样例的场景、问题的ASP表示、问题对应的答案集抽取出来，形成数据集$D$，作为引导LLM进行规则蒸馏的数据源。
随后，对数据集$D$中的第$i$条样例，将其场景$S_i$、问题的ASP查询，与ASP知识库中的所有ASP规则，一同输入Clingo进行求解，
获得答案集$A^*_i$。

如果Clingo求解获得的答案集$A^*_i$与数据集$D$中的答案集$A_i$完全相同，则说明ASP知识库中已经涵盖了足以解决该问题的所有规则，
此时无需再使用LLM进行规则蒸馏。若求解过程中报错或者$A^*_i$与$A_i$并不完全相同，则可认为当前ASP知识库中并不包含解决该问题
所需的全部规则，需要进行规则蒸馏。

规则蒸馏算法的核心包括以下三个环节：预提示、规则生成、规则验证，下面分别展开介绍。

预提示的作用是，为LLM开展后续的规则生成提供背景信息和任务说明，是一组提示词的集合，其包括以下几个方面：
\begin{enumerate}[nosep]
\item \textbf{任务介绍}：简要说明 VQA 任务的背景，告诉 LLM 任务的性质————给定一个问题、
一个图像和它们的描述，生成相应的答案。
\item \textbf{语言语法}：介绍 ASP 规则的基本语法和约定。具体而言，ASP 使用了一些类似于逻辑
程序设计的语法，如:-（表示规则的条件）和 not（表示否定）。
\item \textbf{场景与问题解释}：解释如何将图像场景和问题转换成 ASP 的表示方式。
\item \textbf{答案格式}：告诉LLM如何表示和返回问题的答案。
\item \textbf{初始ASP知识库}：提供初始的ASP知识库$K$，能够回答部分问题，但可能做不到回答所有问题。
\item \textbf{任务说明}：解释LLM在预提示之后将接收的输入以及用户预期的响应。
\end{enumerate}
以上各部分提示词的详细设计方案在附录\ref{appendix:preprompt}中均有介绍。

在向LLM进行预提示之后，进入规则生成环节。此时，将问题的ASP表示、场景一同作为附加提示，要求LLM生成新的ASP规则。
生成的规则是尽可能一般化的规则，即包含更多的变量和较少的常量，以便可以适用于
更广泛的情况。在生成时，可以向LLM直接指明要求其生成尽可能一般化的规则。
一种例如，如果问题是“这只杯子是什么颜色？”，LLM可能会生成以下ASP规则：
\begin{lstlisting}
color_of_cup(Color) :- object(Cup), has_color(Cup, Color), class(Cup,cup).
\end{lstlisting}
这条规则表示：“如果某个物体是杯子，并且它有颜色属性，那么可以推理出它的颜色”。

规则生成之后，需要验证生成的规则是否正确。这一过程需要进行语法
检查、语义检查和回归测试。

语法检查的目的是：检查生成的规则是否符合 ASP 的语法要求。如果规则存在语法错误，
例如拼写错误或格式不对，ASP 解析器将无法解析这些规则。在这种情况下，系统会将错误
信息反馈给 LLM，并要求 LLM 进行规则修正。

语义检查的目的是：检查生成的规则是否能够配合原有规则，获得预期的答案。如果
不能通过语义检查，则采取“反馈+重试”的方法试图进行修正：将Clingo输出的答案与期望的标准答案一同作为追加提示
提供给LLM，并且新的提示词中会明确告知LLM“你之前生成的规则未能得到正确答案，请你根据下面的输入修改规则。”，
LLM会基于原问题、场景、当前规则结果与目标答案的对比，尝试修复逻辑错误或补全缺失的中间推理步骤。
对同一个示例最多允许修正尝试的次数设为m，其默认值为1，表示失败一次就修正一次，防止过多LLM调用。
若修正后仍失败，说明当前LLM无法处理该示例，采取跳过的方法。

语法检查和语义检查都是涉及LLM对ASP程序进行修正，故采用规则修正中经过训练的LLM来完成此处的
语法检查和语义检查任务。

回归测试的目的是：在扩展 ASP 理论的同时，确保新规则不会导致旧问题的答案错误。这
一设计主要基于以下几方面的考量：
\begin{enumerate}[nosep]
\item \textbf{维护系统稳定性和一致性}： 在软件工程中，回归测试被广泛应用于验证新代码的引入
是否影响现有功能的正确性。类似地，在 VQA 系统中，每当通过知识蒸馏添加新规则
时，需要确保这些规则不会干扰系统对先前问题的解答。
\item \textbf{应对模型更新带来的潜在风险}： 知识蒸馏的过程涉及从教师模型向学生模型传递知识，
可能导致学生模型的行为发生变化。通过回归测试，可以检测并防止新知识引入后对模
型性能的负面影响。
\item \textbf{借鉴软件开发中的最佳实践}： 在软件开发中，回归测试是确保新功能或修改不会引入
新错误的关键步骤。将这一理念应用于 VQA 系统，有助于在不断扩展和优化系统的同
时，保持其可靠性和准确性。
\end{enumerate}

回归测试的具体步骤如下：基于更新后的 ASP 理论，重新执行所有历史测试用例，确保
所有旧问题仍然能得到正确答案。如果某个旧问题的答案被破坏，则回退到先前的 ASP 理论，并要求 LLM 重新修正生成的规则。
通过上述设计，回归测试在ASP知识库自动拓展过程中起到了关键的质量保证作用，确
保系统在不断学习和扩展的同时，保持其稳定性和可靠性。

语法检查、语义检查和回归测试这三个环节中，任意一处的修正经多次尝试失败后，系统将视为该问题暂时无法解决，会进行跳过处理，不将该问题用于补充ASP知识库。

规则蒸馏这种基于“最小起点+增量学习”的构建思路，实现了初始ASP知识库向任务完备理论的动态演进，
兼顾了系统可解释性、扩展性与开发效率。
\subsubsection{处理VQA请求时补充ASP知识库的规则蒸馏}
处理VQA请求时补充ASP知识库的规则蒸馏的目的是：当RCNSP的ASP知识库中的知识不足以解决用户提出的积木世界VQA问题时，
基于图像场景的ASP表示、问题的ASP表示，引导LLM自动生成能够解决该问题的ASP规则，并补充到ASP知识库中，以供求解该问题及后续类似问题
使用。

处理VQA请求时补充ASP知识库的规则蒸馏，同样也分预提示、规则生成和规则验证三个环节。预提示部分和RCNSP运行前构造ASP知识库的规则蒸馏
在实现方法上基本相同，主要差别在于提示词中的任务说明部分，此处要求只输出新规则，并且告知LLM后续的输入将包括场景ASP表示。该提示词
具体见附录\ref{appendix:preprompt}中第三组任务说明提示词。
\subsubsection{蒸馏性能优化}
POVQAD训练集中包含数万个样例，如果直接对样本进行蒸馏，既耗时又可能引入冗余信息。
因此，为了提高蒸馏效率，本文提出了样例选择策略，以减少无关数据的干扰。具体而言，包
括以下两种方法：
\begin{enumerate}[nosep]
\item \textbf{谓词计数策略}：该策略根据 ASP 问题表示中谓词的数量对实例进行分组。 分组方法是：
统计每个问题表示中出现的谓词数量，并将具有相同谓词数量的问题归为一组。 通过
这种分组方式，可以根据问题的复杂度（即涉及的谓词数量）来选择示例。 这有助于
LLM 在训练过程中逐步学习，从处理简单问题（谓词数量少）开始，逐步过渡到复杂问
题（谓词数量多），从而提高生成规则的准确性和泛化能力。
\item \textbf{谓词相关性策略}：该策略根据 ASP 问题表示中涉及的具体谓词对实例进行分组。分组
方法是： 识别每个问题表示中出现的谓词，并将包含相同谓词的问题归为一组。 通过
这种分组方式，可以确保 LLM 针对特定谓词学习相关规则。 这有助于 LLM 深入理解
每个谓词的作用和使用场景，从而生成更精确的 ASP 规则，提升 VQA 系统在处理涉及
特定谓词的问题时的表现。
\end{enumerate}

为了进一步提高效率，本文还提出了批量优化策略，即一次性给 LLM 多个示例，而不是
逐个示例地生成规则。这一策略借鉴自 Ge\cite{ge2021selfdistillationbatchknowledgeensembling} 等人提出的批量知识集成的自蒸馏方法。 在知
识蒸馏领域，批量知识集成方法通过在同一小批量内传播和整合样本间的知识，生成更精确
的软目标，从而提升模型性能。此外，自蒸馏方法利用模型自身的预测作为训练目标，减少
对外部教师模型的依赖，简化训练流程。

采用批量优化策略，具有以下几点突出优势：
\begin{enumerate}[nosep]
\item \textbf{提高训练效率}： 通过在同一批次内处理多个样本，模型可以并行学习不同样本的特征
和模式，减少训练时间。
\item \textbf{增强模型泛化能力}：批量优化允许模型在一个批次内接触多样化的数据，帮助模型学习
更广泛的特征表示，从而提升对未见数据的适应能力。
\item \textbf{优化资源利用}：通过批量处理，能够更有效地利用计算资源，减少训练过程中的开销。
\end{enumerate}

综合来看，批量优化策略通过借鉴批量知识集成和自蒸馏等方法，实现了提升知识蒸馏过程中的训练效率和模型性能。
\subsection{ASP推理}
ASP推理阶段中，ASP求解器接收经过优化后的ASP查询语句、视觉场景理解模块提取的ASP事实、环境约束以及自动拓展的ASP规则，
进行逻辑推理，最终获得答案。
本文使用Clingo求解器来进行求解，其工作过程分为基础化（grounding）阶段和求解（solving）阶段。

基础化阶段将ASP程序中的变量替换为常量，生成一个新的ASP程序。Clingo
通过使用内置的基础化器分析程序，生成所有可能的规则。例如，对规则
$a(X) :- b(X), not c(X).$，其将被展开为所有可能的值为X的实例。

求解阶段中，Clingo采用类似SAT求解器的冲突驱动答案集求解（CDNL）方法。CDNL方法通过迭代地添加约束，
直到找到一个满足所有约束的解，或者证明无解。
具体而言，Clingo基于如下步骤进行求解：（1）初始化。从空分配开始（没有原子被标记为真）；
（2）选择与分配。选择一个未分配的原子，猜测其真值为真或假；
（3）传播。根据当前分配和规则，推导其他原子的真值。例如，若规则$a :- b, not c.$满足，b为真且c不在答案集中，则a必须为真；
（4）冲突检测。若分配导致规则冲突（如与已有的约束条件相抵触），记录冲突原因；
（5）回溯与学习。若发生冲突，回溯到之前的选择点，学习冲突子句以避免未来类似错误；
（6）验证。当所有原子分配完成后，检查是否为答案集，即确保它是程序的模型，且最小化（无子集也能满足规则）。

相比其它的ASP求解器，Clingo在以下几个方面进行了优化：（1）从冲突中学习
新的规则，为将来进一步的搜索提供指导；（2）使用多线程实现并行化，同时搜索
多个路径，加速求解过程；（3）使用启发式方法决定分配顺序，例如优先选择高影响力的原子；
（4）预测可能发生的冲突，选择可能导致冲突的原子优先分配，减少搜索空间。
\subsection{求解结果翻译}
经过Clingo得到的输出结果，以形式化的ASP谓词表示，难以直接为最终用户所理解，对用户而言并不友好，需要将其转为自然语言。
Clingo输出的是由逻辑谓词构成的答案集，例如谓词\texttt{left(A,B)}表示“A位于B的左侧”。
由于正常情况下，Clingo输出的都是预先定义的谓词，故采用构造同义词字典的方案，将ASP中的逻辑谓词与自然语言
表述对应起来，作为模板对LLM进行提示。LLM可基于这些模板对解析后的逻辑结果进行填充和修正，生成标准化且易于理解的描述。
本文分析了POVQAD的问题和场景中所用到的谓词，设计了同义词字典，具体见附录\ref{appendix:result-translate}。
\section{实验分析}
本节对4.2节中语义解析、规则修正、规则蒸馏这三个环节分别进行实验，验证各部分的性能。
\subsection{语义解析}
本实验目的包括两方面：（1）评估针对语义解析模块设计的提示词优化策略在积木世界场景下的语义解析任务中的有效性，比较优化前后对LLM输出ASP程序质量的影响；
（2）验证语义解析模块在不同LLMs上的泛化能力。

实验所用的数据集为POVQAD中的验证集，记为$D$。由于语义解析模块接收的输入为自然语言问题，输出为ASP程序，故只需选用
POVQAD中第$i$条样例的$Q_i$中的自然语言问题和问题的ASP查询。

在实验中，本文如下设计了3组提示策略：
\begin{table}[H]
\centering
\caption{语义解析实验的3组提示策略}
\begin{tabular}{|l|p{5.5cm}|p{5.5cm}|}
\hline
\textbf{组别} & \textbf{提示策略} & \textbf{描述} \\
\hline
基线方法 & 零样本提示 & 仅用一句指令提示任务目标，无示例对 \\
\hline
人工少样本方法 & 人工构造少样本示例 & 直接提供设计的所有提示词，由LLMs自主学习 \\
\hline
优化提示词方法 & DSPy的FewShotPromptOptimizer优化提示 & 在验证集监督下自动优化少样本组合 \\
\hline
\end{tabular}
\end{table}
基线方法中，通过直接向LLMs发送任务指令以及验证集$D$中的自然语言问题，考察LLMs自身固有的根据问题生成ASP程序的能力。
人工少样本方法中，首先向LLMs发送人工设计的所有提示词，并指示LLMs学习如何进行ASP程序生成。随后，再向LLMs发送任务指令以及验证集$D$中的自然语言问题，
考察LLMs自主根据提示词学习的能力。
此外，本文将以上3组提示策略均在DeepSeek-R1 Coder、LLaMA3和ChatGPT分别使用，以验证在不同LLMs上的泛化能力。
3种LLM中，既包含DeepSeek-Coder这类轻量级专用模型，也涵盖ChatGPT-4o这类
通用型先进系统，而LLaMA3性能和效率之间取得了平衡，属于居中水平的模型，选取的都是有代表性的LLM，增强实验说服力和可信度。

考核指标选用语法正确率以及语义正确率，在前文中已经有过定义，此处不再赘述。
实验环境的配置方面，CPU为Intel Core i9 12900K，内存为128GB，显卡为2张Nvidia RTX 4090。
另外在实验过程中，对实验重复进行5次，以降低LLM采样过程的随机性带来的影响。

从表\ref{tab:semantic-result}可见，随着提示策略从“零样本”逐步过渡到“人工少样本”再到“优化提示词”，
三种LLM在语法正确率和语义正确率上均表现出持续而显著的提升。
这一趋势表明提示设计对语义解析任务效果具有关键影响。基于实验结果，可进一步分析得出以下几点核心结论：
\begin{enumerate}[nosep]
\item 提示词优化显著优于人工设计，验证提示词可优化性强。
与仅依赖人类经验的提示词设计相比，采用DSPy中的FewShotPromptOptimizer所生成的提示组合在所有模型上均带来了显著性能提升，平均提升语法正确率9.3\%，语义正确率9.9\%。这表明提示词设计不是一个静态、靠直觉决定的过程，而是一个可调优、可搜索的学习问题。
尤其在逻辑程序生成这类输出结构明确、出错容忍度低的任务中，自动优化策略能够更系统性地搜索到最优示例组合，超越人类经验所能涵盖的局限。
\item 上下文顺序与示例排列对模型生成有深远影响。
DSPy优化后的提示并不仅仅在内容上有改进，更关键的是其在提示顺序和上下文组织方式上更契合LLM的偏好。实验结果表明，示例顺序的不同对生成质量影响显著，提示优化工具通过自动组合和排列示例，有效激发了模型对结构性信息的学习能力。这种上下文“协同增强效应”在人工设计的提示中往往难以被系统把握。
\item 提示优化在结构化生成任务中的效果尤为显著。
逻辑程序生成（如ASP）相较于开放式生成任务（如问答或摘要），对输出的结构、语法和语义一致性有更高要求。提示词优化在这种低容错任务中的收益尤其明显。
优化后的提示组合能在多个层面（结构一致性、表达清晰度、语义覆盖性）上统一输出格式，使得LLM能够稳定地输出符合语法和语义的ASP程序，显著减少了因不规范格式或错误逻辑导致的生成失败。
\item 模型能力与提示策略之间存在协同效应。
不同LLM对提示策略的响应程度不同，但均表现出一致的改进趋势。尤其在性能更强的ChatGPT-4o中，优化提示词方法取得了语法正确率96.2\%、语义正确率93.3\%的表现，进一步说明：
在基础模型能力较强的前提下，提示优化策略更容易发挥出色效果；
优化提示策略不仅提升了“弱模型”的基础能力，还能进一步激发“强模型”的潜力，使其在结构化任务中更可靠。
\end{enumerate}
\begin{table}[h]
    \centering
    \begin{tabular}{lcc}
        \toprule
        \textbf{组别} & \textbf{语法正确率} & \textbf{语义正确率} \\
        \midrule
        \multicolumn{3}{c}{\textbf{DeepSeek-Coder 1.3B}} \\
        基线方法 & 42.4\% & 40.1\%\\
        人工少样本方法 & 52.7\% & 48.4\% \\
        优化提示词方法 & 61.8\% & 57.6\% \\
        \midrule
        \multicolumn{3}{c}{\textbf{LLaMA3 70B}} \\
        基线方法 & 65.7\% & 58.2\% \\
        人工少样本方法 & 78.2\% & 77.1\% \\
        优化提示词方法 & 89.6\% & 86.8\% \\
        \midrule
        \multicolumn{3}{c}{\textbf{ChatGPT-4o}} \\
        直接提问 & 77.5\% & 76.2\% \\
        人工少样本方法 & 88.7\% & 82.4\% \\
        优化提示词方法 & 96.2\% & 93.3\% \\
        \bottomrule
    \end{tabular}
    \caption{语义解析中三种提示策略在不同LLMs上的表现}
    \label{tab:semantic-result}
\end{table}

综合来看，本实验不仅验证了提示优化策略在积木世界语义解析任务中的显著优势，也揭示了提示设计的三个关键要素：
示例内容的有效性、示例顺序的敏感性与任务结构性的适配性。
这些发现对于今后在其他领域的结构化语言生成任务（如SQL生成、代码补全、形式化问答）中设计高效提示策略具有重要参考价值。
\subsection{规则修正}
本实验目的包括两方面：（1）评估针对规则修正模块的提示词优化策略在积木世界场景下的规则修正任务中的有效性，比较优化前后对LLM修正ASP程序质量的影响；
（2）验证规则修正模块在不同LLMs上的泛化能力。

实验所用的数据集为人工构造的ASP错误程序集，记为$E$。该数据集的构造目标是：构造一组三元组数据\texttt{（错误的ASP程序，问题文本，修正后的ASP程序）}。
这些样例数据可以作为输入-反馈对，用于提示词优化过程中的\texttt{FewShotPromptOptimizer}。

$E$的构造按照如下步骤进行：
\begin{enumerate}[nosep]
\item 从POVQAD中采样一批VQA问题及其标准ASP程序，对POVQAD中第$i$条样例，选取$Q_i$的自然语言问题以及该问题对应的ASP查询
，组合构成$E$中某条样例数据$e_i$，形式如下：
\begin{lstlisting}
问题: What color is the red cube on the left?
正确程序ₜ:
:- not color(obj1, red).
:- left(obj1, obj2).
:- shape(obj1, cube).
\end{lstlisting}
\item 向正确的ASP程序中人为引入可控错误，获得错误ASP程序$W$。根据前述章节中总结的常见ASP错误类型，此处引入的错误种类包括以下几种：
语法错误、基础化错误、逻辑错误、谓词未定义、负循环依赖。
\item 执行错误程序$W$并筛选语义正确样本。对每个$W$，使用Clingo执行该程序，保留那些程序语法正确但语义错误的样本（即可以执行但输出错误答案的），再排除
语法错误或者无解的极端样本。
\item 构造训练样本对，对某条完整的训练样本，形式如下：
\begin{lstlisting}
指令：以下ASP程序存在错误，请结合问题文本进行修改。
问题：What color is the red cube on the left?
错误程序：
:- not color(obj1, red).
:- right(obj1, obj2). 
:- shape(obj1, cube).
正确程序：
:- not color(obj1, red).
:- left(obj1, obj2).
:- shape(obj1, cube).
\end{lstlisting}
\end{enumerate}

在实验中，本文如下设计了3组提示策略：
\begin{table}[H]
\centering
\caption{规则修正实验的3组提示策略}
\begin{tabular}{|l|p{5.5cm}|p{5.5cm}|}
\hline
\textbf{组别} & \textbf{提示策略} & \textbf{描述} \\
\hline
基线方法 & 零样本提示 & 仅用一句指令提示任务目标，无示例对 \\
\hline
人工少样本方法 & 人工构造少样本示例 & 直接提供设计的所有提示词，由LLMs自主学习 \\
\hline
优化提示词方法 & DSPy的FewShotPromptOptimizer优化提示 & 在验证集监督下自动优化少样本组合 \\
\hline
\end{tabular}
\end{table}
基线方法中，通过直接向LLMs发送任务指令以及验证集$D$中的自然语言问题，考察LLMs自身固有的修正ASP程序的能力。
人工少样本方法中，首先向LLMs发送人工设计的所有提示词，并指示LLMs学习如何进行ASP规则修正。随后，再向LLMs发送任务指令以及验证集$E$中的规则修正示例，
考察LLMs自主根据提示词学习的能力。
此外，本文将以上3组提示策略均在DeepSeek-R1 Coder、LLaMA3和ChatGPT分别使用，以验证在不同LLMs上的泛化能力。

考核指标选用三轮以内修复成功率以及修复后语义正确率。
实验环境的配置方面，CPU为Intel Core i9 12900K，内存为128GB，显卡为2张Nvidia RTX4090。
另外在实验过程中，对实验重复进行5次，以降低LLM采样过程的随机性带来的影响。

从表\ref{tab:rule-fix-result}中可以清晰地看出，三种提示策略在不同LLMs上的表现差异显著，进一步印证了提示词设计对规则修正任务效果的核心影响。实验结果支持以下几个关键观察与结论：
\begin{enumerate}[nosep]
\item 提示词优化显著提升结构化修复任务表现。在所有模型中，优化提示词方法（基于DSPy的FewShotPromptOptimizer）在三轮以内修复成功率和修复后语义正确率方面均表现最佳。例如，在ChatGPT-4o上，修复成功率从人工少样本的82.7\%进一步提高到86.6\%，语义正确率从79.1\%提升至85.5\%。
这表明，对于结构化输出任务（如ASP规则修正），自动提示词优化技术能够从提示内容与顺序两个维度，组合出最适合当前任务的示例，从而显著提升LLMs的指令遵循与结构生成能力。
\item 规则修正比语义解析更依赖示例结构与对抗性上下文。与语义解析任务相比，规则修正任务具有更强的“对比性上下文”特征：模型不仅要理解语法和语义规则，还要在错误程序与问题文本的对照关系中定位错误并修复。
这一特性对提示结构和示例的显式差异性（如“错误-正确”配对）提出更高要求，简单的指令式提示在此任务中显得尤为不足。优化提示能够更系统性地引导模型学会识别典型错误模式与对应修复策略，因此收效显著。
\item LLM能力与提示词策略之间存在非线性关系。不同模型之间对提示策略的响应能力不同，提示优化带来的相对提升幅度也有所差异。例如，ChatGPT-4o的性能基线已较高，优化提示提升空间有限；但在DeepSeek-Coder等中小模型上，优化提示策略带来的提升更加明显（如语义正确率提升超10%）。
这表明，提示优化策略在中小模型中补全能力缺口的作用更为显著，而在大型模型中则更多发挥微调或增强特定能力的作用。
\item 优化策略对多轮修复交互的有效性也有正面影响。本实验中引入“三轮以内修复成功率”作为指标，实质上是评估LLMs在多轮自我修正流程中的“收敛速度”。优化提示显著提升了该指标，说明模型在提示优化后更容易快速找准错误关键，减少无效修复轮次，从提示到正确结构输出的路径更短、更稳定。
\end{enumerate}
\begin{table}[h]
    \centering
    \begin{tabular}{lcc}
        \toprule
        \textbf{组别} & \textbf{三轮以内修复成功率} & \textbf{修复后语义正确率}\\
        \midrule
        \multicolumn{3}{c}{\textbf{DeepSeek-Coder 1.3B}} \\
        基线方法 & 56.3\% & 50.3\%\\
        人工少样本方法 & 69.7\% & 62.1\% \\
        优化提示词方法 & 76.6\% & 72.8\% \\
        \midrule
        \multicolumn{3}{c}{\textbf{LLaMA3 70B}} \\
        基线方法 & 58.1\% & 57.9\% \\
        人工少样本方法 & 68.9\% & 60.6\% \\
        优化提示词方法 & 72.2\% & 65.1\% \\
        \midrule
        \multicolumn{3}{c}{\textbf{ChatGPT-4o}} \\
        直接提问 & 71.9\% & 71.5\% \\
        人工少样本方法 & 82.7\% & 79.1\% \\
        优化提示词方法 & 86.6\% & 85.5\% \\
        \bottomrule
    \end{tabular}
    \caption{规则修正中三种提示策略在不同LLMs上的表现}
    \label{tab:rule-fix-result}
\end{table}

本节实验结果进一步验证了提示词优化方法在结构性语言任务中的有效性。不同于开放式生成任务，规则修正任务对结构、语义、语法的三重一致性
要求极高，因此更依赖清晰、精准、系统性强的提示策略。通过引入DSPy的优化机制，不仅显著提升了模型对错误ASP程序的修正能力，
也在多模型、多错误类型条件下展现出广泛适应性与稳健性，为提示自动优化在逻辑程序生成任务中的应用提供了强有力的实证支持。
\subsection{规则蒸馏}
规则蒸馏实验的目的为：评估本文设计的规则蒸馏方法对提升部分可见积木世界场景下空间推理问答准确率的效果，并证明规则蒸馏方法在不同的LLMs上的泛化能力。

为了达到上述实验目的，本节实验对象选取目前主流的三种LLM：DeepSeek-Coder、LLa\-MA3和ChatGPT-4o。
以上既包含DeepSeek-Coder这类轻量级专用模型，
也涵盖ChatGPT-4o这类通用型先进系统，而LLaMA3性能和效率之间取得了平衡，属于居中水平的模型。
在多个基座上进行实验，可以有效证明RCNSP对不同LLM的泛化能力。
实验数据集选取本文第三章构建的POVQAD，将每条样本的图像、自然语言问题输入RCNSP，与每条样本的答案进行对比，计算
回答正确率。实验环境的配置方面，CPU为Intel Core i9 12900K，内存为128GB，显卡为2张Nvidia RTX 4090。

模型一采用直接向 VLM 提问的方式，即将自然语言问题与图像一同输入 VLM，并不给予任何的额外提示。
直接提示VLM的方式虽然简单，却是评估模型的关键基准，因为直接提示方法能够反映模型在没有任何
外部推理辅助机制的情况下，自身对空间问题的处理能力。

模型二为原始框架方法，实际上相当于去除规则蒸馏模块的RCNSP。Wang等人设计的原始框架\cite{wang2024DSPy}，是对StepGame、SparQA这种纯文本空间推理数据集
中的问题进行推理解答，不包括视觉场景理解，不支持多模态的输入。故去除规则蒸馏模块的RCNSP实际上相当于Wang等人设计的
框架的支持多模态输入的版本，使其能够顺利在第\ref{dataset}章设计的空间推理数据集上进行实验，
进而与本文添加规则蒸馏模块后的RCNSP框架形成对比。

表\ref{tab:overall_comparison}展示了三种不同模型在三种不同方法下的问答正确率表现，结果表明本文提出的 RCNSP 框架在多种模型上均显著提升了部分可见积木世界中的空间推理问答准确率，具体分析如下：
\begin{enumerate}[nosep]
\item RCNSP 在所有模型中均显著优于原始框架，验证规则蒸馏方法有效性。
在 DeepSeek-Coder 1.3B、LLaMA3 70B 和 ChatGPT-4o 三种模型上，RCNSP 相较于去除规则蒸馏模块的原始框架，分别带来了 9.3\%、9.4\%、8.2\% 的准确率提升，平均提升为 8.96\%，
这一结果表明本文提出的规则蒸馏机制能够稳定提高模型的空间推理能力，特别是在处理部分可见场景中具有高度抽象性与遮挡干扰的问题时，
RCNSP 能够从图像中提取更具结构化的信息表示，进一步提升逻辑推理准确率。
\item RCNSP 明显优于直接提问策略，体现神经符号框架的推理优势。“直接提问”方法是空间问答中最简便的方式，仅依赖 VLM 自身能力，
不借助外部结构化表示或推理机制。然而，该方法在三种模型中的平均准确率仅为 65.5\%，相比之下，RCNSP 的平均准确率为 82.1\%，高出 16.6\%。
这说明当前主流大模型（即便是如 ChatGPT-4o 这类最先进模型）在直接进行空间关系理解与推理时仍存在一定局限，
尤其面对结构复杂、部分可见、遮挡严重的图像时，性能存在明显瓶颈。
神经符号架构通过将图像理解、结构化建模、逻辑推理等模块解耦组合，能有效提升空间关系建模的清晰度，
补足了通用LLMs在空间推理细粒度上的弱点。
\item RCNSP 模型的优势随模型能力提升而增强，具有放大高性能LLM潜力的能力。
从三个模型的性能来看，RCNSP 在 ChatGPT-4o 上的提升（从原始框架的76.6\%提升至84.8\%）依然显著，说明
尽管高性能模型已经具备较强的感知与理解能力，但规则蒸馏模块在此基础上仍有能力进一步挖掘模型潜力，提升边界性能。
这一特点对于未来大模型的集成系统具有现实意义：RCNSP 可作为高阶“空间推理增强器”，在 VQA、机器人操作等任务中提升表现。
\end{enumerate}
\begin{table}[h]
    \centering
    \begin{tabular}{lc}
        \toprule
        \textbf{任务类型} & \textbf{正确率} \\
        \midrule
        \multicolumn{2}{c}{\textbf{DeepSeek-Coder 1.3B}} \\
        直接提问 & 59.4\% \\
        原始框架方法 & 72.5\% \\
        RCNSP & 81.8\% \\
        \midrule
        \multicolumn{2}{c}{\textbf{LLaMA3 70B}} \\
        直接提问 & 65.7\% \\
        原始框架方法 & 70.2\% \\
        RCNSP & 79.6\% \\
        \midrule
        \multicolumn{2}{c}{\textbf{ChatGPT-4o}} \\
        直接提问 & 71.5\% \\
        原始框架方法 & 76.6\% \\
        RCNSP & 84.8\% \\
        \bottomrule
    \end{tabular}
    \caption{不同模型及方法在各问题类型上的表现}
    \label{tab:overall_comparison}
\end{table}

综上所述，实验充分验证了 RCNSP 所引入的规则蒸馏机制在部分可见空间推理问答任务中的有效性和泛化能力。
与直接提问和原始框架相比，RCNSP 在所有模型上都取得了显著性能提升，展现出神经符号框架在复杂空间场景下结构感知与逻辑推理的强大能力。
\section{本章小结}
本章围绕设计一个规则自动补全的神经符号VQA框架的目标，从设计方案、核心技术及实现与实现分析三方面进行展开。

首先，介绍了RCNSP设计方案。以RSNSP总体设计方案为统领，
对各个模块的功能、技术方法、研究难点和相比已有工作的创新进行了介绍。

其次，介绍了RCNSP核心技术及实现。针对RCNSP中视觉场景理解、语义解析、规则修正、规则蒸馏、ASP推理、求解结果翻译
这六个核心模块进行了详细阐述。特别是对于语义解析、规则修正和规则蒸馏这三个模块进行了重点描述。

最后，进行了实验分析。在第三小节中，本文对语义解析、规则修正与规则蒸馏三个核心模块进行实验，
从实验目的、实验数据、实验方法、实验环境及实验结果分析上进行了阐述。
实验结果表明，本文针对部分可见积木世界场景下的空间推理任务的特点设计的提示词优化方案对ASP规则生成、规则修正的准确率上
具有显著提升作用，也证明了本文设计的规则蒸馏方法可以显著提升部分可见积木世界场景下空间推理问答准确率，
同时也验证了RCNSP在不同LLMs上的泛化能力。

本章的RCNSP为后续开发面向自动规划教学的积木世界VQA演示原型系统奠定了坚实基础。