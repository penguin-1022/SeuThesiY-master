%===============================================================================
\categorynumber{000} % 分类采用《中国图书资料分类法》
\UDC{000}            %《国际十进分类法UDC》的类号
\secretlevel{公开}    %学位论文密级分为"公开"、"内部"、"秘密"和"机密"四种
\studentid{222171}   %学号要完整，前面的零不能省略。
\title{积木世界VQA中的}{积木世界VQA中的}{空间推理问答技术研究与实现}{空间推理问答技术研究与实现}{Research and Implementation of Spatial Reasoning Questioning Answering Techniques }{in the Block World VQA}
\author{贾梁}{Jia Liang}
\advisor{张志政}{}{Zhang Zhizheng}{}
% \coadvisor{张志政}{副教授}{Zhang Zhizheng}{Associate Prof.} % 没有% 可以不填
\degreetype{工程硕士}{Master of Engineering} % 详细学位名称
\thesisform{应用研究} % 包括应用研究、调研报告、规划、产品开发、案例分析、项目管理、文学艺术作品、其它。非专业型硕士可忽略
\major{电子信息}
\submajor{计算机技术}
\defenddate{2025年5月30日}
\authorizedate{2025年6月20日}
\committeechair{翟玉庆}
\reviewer{倪庆剑}{张祥}
\department{东南大学计算机科学与工程学院}{School of Computer Science and Engineering}
\makebigcover
\makecover
\begin{abstract}{回答集编程，视觉问答，空间推理，神经符号方法}
积木世界是人工智能研究、教学、实验、评估的重要场景，能够模拟实际应用中物体间的空间关系。
积木世界VQA要求视觉语言模型（Visual Language Model, VLM）具备空间推理能力，但已有研究表明，当面对部分可见场景时，
其回答准确率显著下降。目前，通过结合神经网络和符号推理形成的神经符号模型，利用深度学习将视觉信息转化为逻辑符号，
再利用符号推理进行问题求解问题，比单纯依赖深度学习的视觉语言模型在空间推理任务中有更优异的表现。
由于回答集程序（Answer Set Program, ASP）是一种具备非单调推理和高效推理机的符号推理方法，
神经符号模型中采用ASP构建的神经符号VQA框架被寄予厚望。然而，现有框架设计中ASP规则的扩展仍依赖人工，
难以有效应对部分可见场景中基于空间推理的VQA任务。
    
针对上述问题，本文从构建积木世界部分可见场景中基于空间推理的VQA数据集、
设计规则自动补充的神经符号VQA方法、设计实现VQA课堂演示原型系统三个方面开展工作，具体如下：

\begin{enumerate}[nosep]
\item 部分可见积木世界场景空间推理VQA数据集（Partial Observation VQA Dataset, POVQA\-D）构建。
CLEVR是积木世界的经典数据集，然而CLEVR中问题涉及的物体属性和物体间空间关系在图像中均完全可见，
通过引入部分可见性与环境约束，构建了覆盖部分场景可见问题的VQA数据集POVQAD。
POVQAD要求模型能够利用背景知识和部分可见场景中的信息进行推理
，比原数据集更能有效考察模型在部分可见积木世界场景中回答空间推理问题的能力。
\item 规则自动补充的神经符号VQA框架（Rule Complement Neuro-Symbolic Pipeline, RCNSP）设计。
RCNSP借鉴现有神经符号VQA框架的工作，对LLM进行提示词优化以提高ASP规则生成、规则修正的语法及语义准确率，
并新增规则蒸馏模块以实现ASP规则自动拓展。
实验表明，在DeepSeek、LLaMA3、ChatGPT-4o三种大语言模型上，使用RCNSP比直接向VLM提问的准确率平均提升16.5\%，
比现有的神经符号VQA框架的准确率平均提升8.9\%，
表明通过规则蒸馏能有效提升神经符号方法在部分可见积木世界场景下空间推理问答的准确率。
\item 设计实现了一个积木世界VQA原型系统。在RCNSP框架和POVQAD数据集基础上，设计实现了一个
积木世界VQA原型系统。
该系统模拟了在自动规划课程的授课场景下，由教师向系统提出积木世界的空间推理问题，系统进行解答并展示推理的中间步骤和逻辑链条，
并支持自定义生成复杂度不同的演示数据集，
为教师向学生展示智能体如何理解外部环境信息并进行规划提供了便利。
初步测试表明该系统在CPU为Intel Core i9-12900K，内存128G，显卡为3张RTX 3090并联的硬件环境下，并发量为38，
90\%响应时间为6.9秒，能够满足自动规划课程教学场景下的用户需要。
\end{enumerate}
\end{abstract}

\begin{englishabstract}{Answer Set Programming, Visual Question Answering, Spatial Reasoning, Neuro-symbolic Method}
The Block World is a fundamental scenario for research, education, experimentation, and evaluation in artificial intelligence, capable of simulating spatial relationships among objects in real-world applications. Block World Visual Question Answering (VQA) tasks require Visual Language Models (VLMs) to possess spatial reasoning capabilities. However, existing studies have shown that the accuracy of VLMs significantly drops in partially observable environments. Neuro-symbolic models, which integrate neural networks and symbolic reasoning, convert visual information into logical symbols using deep learning and solve problems through symbolic inference. These models have demonstrated superior performance in spatial reasoning tasks compared to purely neural-based VLMs.

Answer Set Programming (ASP), a symbolic reasoning paradigm with non-monotonic reasoning and efficient solvers, has been widely adopted in neuro-symbolic VQA frameworks. However, current frameworks still rely heavily on manual rule construction, making it difficult to handle spatial reasoning tasks in partially observable scenarios effectively.

To address this issue, this work focuses on three main aspects: constructing a spatial reasoning VQA dataset under partial observability in Block World, designing a neuro-symbolic VQA method with automatic rule augmentation, and developing a classroom demonstration prototype system for VQA. Specifically:

\begin{enumerate}[nosep]
\item \textbf{Construction of the Partial Observation VQA Dataset (POVQAD):}  
CLEVR is a classical dataset for spatial reasoning, but all object attributes and spatial relations in its scenes are fully visible. We introduce partial observability and environmental constraints to construct POVQAD, a dataset that challenges models to reason with background knowledge and limited visual input. Compared to existing datasets, POVQAD better evaluates a model's capability in answering spatial reasoning questions under partial observability in the Block World.

\item \textbf{Design of the Rule Complement Neuro-Symbolic Pipeline (RCNSP):}  
RCNSP builds upon existing neuro-symbolic frameworks and enhances large language models (LLMs) with prompt optimization to improve the syntactic and semantic accuracy of ASP rule generation and correction. Furthermore, it introduces a rule distillation module to automatically expand ASP rules. Experiments with DeepSeek, LLaMA3, and ChatGPT-4o demonstrate that RCNSP improves the average accuracy by 16.5\% over direct VLM questioning and by 8.9\% over existing neuro-symbolic VQA frameworks. These results confirm that rule distillation significantly enhances the spatial reasoning accuracy in partially observable Block World scenarios.

\item \textbf{Implementation of a Block World VQA Prototype System:}  
Based on the RCNSP framework and the POVQAD dataset, a prototype system for Block World VQA is implemented. This system simulates classroom teaching of automated planning, where instructors pose spatial reasoning questions to the system. The system provides answers along with intermediate reasoning steps and logical chains, helping students understand how intelligent agents perceive and plan in their environments. Preliminary tests show that on a system with an Intel Core i9-12900K CPU, 128GB RAM, and three RTX 3090 GPUs, the system supports a concurrency of 38 with a 90\% response time of 6.9 seconds, meeting the performance requirements of educational scenarios in automated planning.
\end{enumerate}
\end{englishabstract}

\setnomname{术语与符号约定}
\tableofcontents
\listofothers
%===============================================================================
