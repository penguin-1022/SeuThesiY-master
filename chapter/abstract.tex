%===============================================================================
\categorynumber{000} % 分类采用《中国图书资料分类法》
\UDC{000}            %《国际十进分类法UDC》的类号
\secretlevel{公开}    %学位论文密级分为"公开"、"内部"、"秘密"和"机密"四种
\studentid{222171}   %学号要完整，前面的零不能省略。
\title{积木世界VQA中的}{积木世界VQA中的}{空间推理问答技术研究与实现}{空间推理问答技术研究与实现}{Research and Implementation of Spatial Reasoning Questioning Answering Techniques }{in the Block World VQA}
\author{贾梁}{Jia Liang}
\advisor{张志政}{}{Zhang Zhizheng}{}
% \coadvisor{张志政}{副教授}{Zhang Zhizheng}{Associate Prof.} % 没有% 可以不填
\degreetype{工程硕士}{Master of Engineering} % 详细学位名称
\thesisform{应用研究} % 包括应用研究、调研报告、规划、产品开发、案例分析、项目管理、文学艺术作品、其它。非专业型硕士可忽略
\major{电子信息}
\submajor{计算机技术}
\defenddate{2025年5月30日}
\authorizedate{2025年6月20日}
\committeechair{翟玉庆}
\reviewer{倪庆剑}{张祥}
\department{东南大学计算机科学与工程学院}{School of Computer Science and Engineering}
\makebigcover
\makecover
\begin{abstract}{回答集编程，视觉问答，空间推理，神经符号方法}
积木世界是人工智能研究、教学、实验、评估的重要场景，能够模拟实际应用中物体间的空间关系。
积木世界VQA要求视觉语言模型（Visual Language Model, VLM）具备空间推理能力，但已有研究表明，当面对部分可见场景时，
其回答准确率显著下降。目前，通过结合神经网络和符号推理形成的神经符号模型，利用深度学习将视觉信息转化为逻辑符号，
再利用符号推理进行问题求解问题，比单纯依赖深度学习的视觉语言模型在空间推理任务中有更优异的表现。
由于回答集程序（Answer Set Program, ASP）是一种具备非单调推理和高效推理机的符号推理方法，
神经符号模型中采用ASP构建的神经符号VQA框架被寄予厚望。然而，现有框架设计中ASP规则的扩展仍依赖人工，
难以有效应对部分可见场景中基于空间推理的VQA任务。
    
针对上述问题，本文从构建积木世界部分可见场景中基于空间推理的VQA数据集、
设计规则自动补充的神经符号VQA方法、设计实现VQA课堂演示原型系统三个方面开展工作，具体如下：

\begin{enumerate}[itemsep=0pt]
\item 部分可见积木世界场景空间推理VQA数据集（Partial Observation VQA Dataset, POVQA\-D）构建。
CLEVR是空间推理的经典数据集，然而CLEVR中问题涉及的物体属性和物体间空间关系在图像中均完全可见，
通过引入部分可见性与环境约束，构建了覆盖部分场景可见问题的VQA数据集POVQAD。
POVQAD要求模型利用背景知识和部分可见场景中的信息进行推理
，比原数据集更能有效考察模型在部分可见积木世界场景中回答空间推理问题的能力。
\item 规则自动补充的神经符号VQA框架（Rule Complement Neuro-Symbolic Pipeline, RCNSP）设计。
RCNSP借鉴现有神经符号VQA框架的架构，新增规则蒸馏模块，
实现在ASP求解器进行推理前调用微调后的大语言模型自动对规则进行补充。
实验表明，在DeepSeek、LLaMA3、ChatGPT-4o三种大语言模型上，使用RCNSP比直接向VLM提问的准确率平均提升16.5\%，
比现有的神经符号VQA框架的准确率平均提升8.9\%，表明通过规则蒸馏能有效提升神经符号方法在部分可见积木世界场景下空间推理问答的准确率。
\item 设计实现了一个积木世界VQA原型系统。在RCNSP框架和POVQAD数据集基础上，设计实现了一个
积木世界VQA原型系统。
该系统模拟了在自动规划课程的授课场景下，由教师向系统提出积木世界的空间推理问题，系统进行解答并展示推理的中间步骤和逻辑链条，
为教师向学生展示智能体如何理解外部环境信息并进行规划提供了便利。
初步测试表明该系统在CPU为Intel Core i9-12900K，内存128G，显卡为3张RTX 3090并联的硬件环境下，并发量为38，
90\%响应时间为6.9秒，能够满足自动规划课程教学场景下的用户需要。
\end{enumerate}
\end{abstract}

\begin{englishabstract}{Answer Set Programming, Visual Question Answering, Spatial Reasoning, Neuro-symbolic Method}
The block world serves as an important scenario for research, education, experimentation, and evaluation in artificial intelligence, capable of simulating spatial relations among objects in practical applications. Block World Visual Question Answering (VQA) requires Visual Language Models (VLMs) to possess spatial reasoning capabilities. However, existing studies have shown that their accuracy significantly declines when facing partially observable scenes. 

Currently, neuro-symbolic models—combining neural networks and symbolic reasoning—leverage deep learning to translate visual information into logical symbols, followed by symbolic reasoning for problem solving. These models demonstrate superior performance in spatial reasoning tasks compared to purely deep learning-based VLMs. Answer Set Programming (ASP), a symbolic reasoning method characterized by non-monotonic reasoning and efficient solvers, is highly promising for constructing neuro-symbolic VQA frameworks. However, in existing designs, the extension of ASP rules still relies heavily on manual efforts, making it difficult to effectively handle VQA tasks under partial observability conditions.

To address these issues, this thesis focuses on three main contributions: (1) constructing a spatial reasoning VQA dataset under partial observability in the block world; (2) designing a neuro-symbolic VQA method with automatic rule complement; and (3) developing a prototype VQA system for classroom demonstration. The details are as follows:

\begin{enumerate}[itemsep=0pt]
\item \textbf{Construction of the Partial Observation VQA Dataset (POVQAD).} CLEVR is a classical dataset for spatial reasoning; however, in CLEVR, object attributes and spatial relations are fully visible within images. By introducing partial observability and environmental constraints, we constructed POVQAD, a dataset covering VQA tasks involving partially observable scenes. POVQAD requires models to reason by utilizing both background knowledge and limited observable information, providing a more effective evaluation of spatial reasoning capabilities under partial observability.

\item \textbf{Design of the Rule Complement Neuro-Symbolic Pipeline (RCNSP).} Based on existing neuro-symbolic VQA frameworks, RCNSP introduces a rule distillation module. Before invoking the ASP solver for reasoning, RCNSP uses fine-tuned large language models (LLMs) to automatically supplement missing rules. Experiments conducted with DeepSeek, LLaMA3, and ChatGPT-4o demonstrate that RCNSP achieves an average improvement of 16.5\% in accuracy compared to directly querying VLMs, and an average improvement of 8.9\% compared to existing neuro-symbolic VQA frameworks, indicating the effectiveness of rule distillation in enhancing spatial reasoning performance in partially observable block world scenarios.

\item \textbf{Development of a Block World VQA Prototype System.} Based on RCNSP and POVQAD, a prototype system for block world VQA was developed. In the context of teaching automated planning courses, the system allows instructors to pose spatial reasoning questions, with the system answering while displaying intermediate reasoning steps and logical chains. This facilitates demonstrations of how intelligent agents understand and plan about external environments. Preliminary tests show that, under a hardware setup of an Intel Core i9-12900K CPU, 128GB RAM, and three RTX 3090 GPUs in parallel, the system achieves a concurrency of 38 with a 90\% response time of 6.9 seconds, meeting the performance requirements for classroom use.
\end{enumerate}
\end{englishabstract}

\setnomname{术语与符号约定}
\tableofcontents
\listofothers
%===============================================================================
