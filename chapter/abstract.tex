%===============================================================================
\categorynumber{000} % 分类采用《中国图书资料分类法》
\UDC{000}            %《国际十进分类法UDC》的类号
\secretlevel{公开}    %学位论文密级分为"公开"、"内部"、"秘密"和"机密"四种
\studentid{222171}   %学号要完整，前面的零不能省略。
\title{基于回答集编程的}{基于回答集编程}{视觉问答技术研究与实现}{视觉问答技术研究与实现}{Research and implementation of visual question answering technology }{based on answer set programming}
\author{贾梁}{Jia Liang}
\advisor{张志政}{副教授}{Zhang Zhizheng}{Associate Prof.}
% \coadvisor{张志政}{副教授}{Zhang Zhizheng}{Associate Prof.} % 没有% 可以不填
\degreetype{工程硕士}{Master of Engineering} % 详细学位名称
\thesisform{应用研究} % 包括应用研究、调研报告、规划、产品开发、案例分析、项目管理、文学艺术作品、其它。非专业型硕士可忽略
\major{电子信息}
\submajor{计算机技术}
\defenddate{2025年5月30日}
\authorizedate{2025年6月20日}
\committeechair{翟玉庆}
\reviewer{倪庆剑}{张祥}
\department{东南大学计算机科学与工程学院}{School of Computer Science and Engineering}
\makebigcover
\makecover
\begin{abstract}{多模态，回答集编程，视觉问答，空间推理}
    目前，视觉语言模型已在视觉问答、图片描述生成等方面表现出不错的效果，但它们通常在空间推理方面表现不佳，特别是在不完全可见场景下，对空间关系的理解、推理能力较差。
    回答集编程（Answer Set Programming, ASP）是一种形式化的知识表示和推理方法，已有一些研究表明其在理解空间关系和进行空间推理方面，具有较强的能力。
    视觉问答的神经符号系统使用深度学习技术进行感知，生成输入图像和问题的逻辑符号表示，然后使用ASP进行推理，并做出相应回答。相比单独的视觉语言模型，视觉问答的神经符号
    系统在空间推理方面更加出色。然而，现有的考察模型的空间推理能力的视觉问答数据集，存在问题设计较为简单、对象类型和属性单一、问题的语言表达缺乏多样性等问题。
    此外，现有的神经符号系统泛化能力较差，编写、维护提示词的过程过于复杂，开发难度相对较高，且对新场景下的问题需要人为设计额外规则，
    可拓展性较差。为了解决这些问题，本文构建了一个视觉问答数据集，并提出了一种神经符号框架。本文的主要工作如下：
\begin{enumerate}[itemsep=0pt]
    \item 构造了一个视觉问答数据集，该数据集基于CLEVR数据集构建，从推理所需步数、对象类型和属性、问题的语言表达的多样性和模糊性等方面着手，
    增加了数据集的难度，可以更好地考察模型在解决复杂空间推理任务方面的能力。
    \item 设计了一种面向空间推理领域的神经符号框架，实现ASP求解器与大语言模型的系统集成。该框架基于DSPy开发，融合了DSPy自动化提示生成和优化过程的显著优势，架构上包含反馈循环、提示和基于ASP的验证等模块，
增强了视觉问答系统在解决空间推理问题方面的能力。
    \item 基于本文设计的神经符号框架，设计并实现了一个视觉问答领域的神经符号系统。
\end{enumerate}

通过上述工作，本文提出的神经符号框架在提升视觉语言模型的空间推理能力方面，
尤其是在处理复杂和不完全可见场景的问题时，展现出良好的性能和适应性。
    
\end{abstract}

\begin{englishabstract}{Multi-modal, Answer Set Programming, Visual Question Answering, Spatial Reasoning}
    Here is the English translation of the provided text:

Currently, visual language models (VLMs) have demonstrated promising performance in tasks like visual question answering and image caption generation. However, they often exhibit deficiencies in spatial reasoning, particularly in understanding and inferring spatial relationships within partially observable scenes.
Answer Set Programming (ASP), a formal knowledge representation and reasoning method, has shown strong capabilities in comprehending spatial relations and performing spatial reasoning according to prior research. Neurosymbolic systems for visual question answering employ deep learning for perception to generate logical symbolic representations of input images and questions, then utilize ASP for reasoning and response generation. Compared to standalone VLMs, such neurosymbolic systems demonstrate superior spatial reasoning capabilities. Nevertheless, existing visual question answering datasets for evaluating spatial reasoning suffer from oversimplified problem designs, limited object types/attributes, and lack diversity in linguistic expressions.
Moreover, current neurosymbolic systems face challenges including poor generalization, overcomplicated prompt engineering/maintenance processes, high development complexity, and limited scalability requiring manual rule design for new scenarios. To address these issues, this paper constructs a novel VQA dataset and proposes an enhanced neurosymbolic framework. Our main contributions are:
\begin{enumerate}[itemsep=0pt]
    \item We develop a VQA dataset based on CLEVR, significantly increasing complexity through multi-step reasoning requirements, diversified object types/attributes, and enhanced linguistic diversity/ambiguity in question formulations. This dataset better evaluates models' capabilities in handling sophisticated spatial reasoning tasks.
    \item We propose a spatial reasoning-oriented neurosymbolic framework integrating ASP solvers with large language models (LLMs). Developed based on DSPy, this framework leverages DSPy's automatic prompt generation/optimization advantages. Its architecture incorporates feedback loops, prompt engineering modules, and ASP-based verification mechanisms, substantially enhancing spatial reasoning performance in VQA systems.
    \item Building upon this framework, we implement a neurosymbolic system for visual question answering that demonstrates improved capability in solving complex spatial reasoning problems through systematic integration of perception and reasoning components.
\end{enumerate}

Through these efforts, the proposed neural-symbolic framework demonstrates strong performance and adaptability in enhancing the spatial reasoning capabilities of VLMs, especially when handling complex and partially visible scenes.
\end{englishabstract}

\setnomname{术语与符号约定}
\tableofcontents
\listofothers
%===============================================================================
