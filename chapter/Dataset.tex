\chapter{POVQAD数据集构建}
\label{dataset}
本章旨在构建积木世界部分可见空间推理数据集，以便在后续研究中评估本文提出的神经符号VQA框架的性能，为本文的总研究目标服务。
下面分别就构建目标、构建准则、数据集定义、构建流程、数据集质量评估、数据集构建工具共六个方面展开介绍。
\section{构建目标}
本文提出构建一个积木世界部分可见场景空间推理数据集（Partial Observation VQA Data\-set, POVQAD）
，用于后续的研究中评估本文提出的神经符号VQA框架的性能。POVQAD的构建目标为：（1）引入部分可见性；（2）
要求模型在回答POVQAD中的问题时结合背景知识进行综合、全面的作答。以上数据集的构建目标，来源于以下几点：
\begin{enumerate}[nosep]
\item \textbf{CLEVR中场景信息完全可见}：对CLEVR中的某个问题而言，问题中涉及的所有物体，均在该问题对应的图像中
完全可见，不能反映现实世界中由于遮挡、视角限制等因素造成的部分场景可见的情形，不能满足本文研究目标中对于
部分可见积木世界场景的需要。
例如，对于问题“What color is the cylinder to the left of the red sphere?”，
该问题对应的图像中左侧有一个蓝色圆柱体，右侧是红色球体。模型只需定位球体，并找其左侧物体，即可直接读取颜色。
\item \textbf{CLEVR缺少环境级逻辑约束}：CLEVR 场景中不存在“必须满足”的环境约束，
例如“所有红色物体必须是立方体”这类限制，使得推理任务缺乏积木世界空间推理中复杂性的模拟，不能考察模型综合利用背景知识进行系统推理的能力。
例如，对于问题“Are there more cubes than red things?”，
模型只需清点图像中立方体的数量和红色物体的数量即可比较并得出答案，而无需理解任何隐藏的逻辑条件或跨区域限制。
\item \textbf{CLEVR中问题的推理路径较短}：CLEVR中的很多问题只需一步推理或直接感知，不足以检验神经符号VQA框架在
积木世界多跳推理中的表现。例如，对于问题“What is the material of the small red object?”，模型只需要查找
图像中红色且尺寸为小的物体，即可直接回答材质，仅一次推理即可完成，推理路径很短。
\end{enumerate}
具体到数据集的各方面，构建目标可在图像、问题、环境约束、符号表示上进行进一步细化。
\subsection{图像层面目标}
图像层面上，具体包括以下目标：
\begin{enumerate}[nosep]
\item 引入部分可见性。由于CLEVR假设问题中的所有物体在问题对应的图像中都完全可见，
无法评估模型在信息缺失情况下的推理能力，而ASP的优势之一就是推理缺失项\cite{fandinno2021planningincompleteinformationquantified}，通过部分可见积木世界场景来验证本文设计的以ASP为核心的神经符号VQA框架
在空间推理VQA上的有效性。
\item 保证高质量图像生成。本文设计的神经符号VQA框架中包含对图像的识别，需要根据识别出的物体以及物体之间的空间关系，
生成ASP规则以便后续针对不可见物体进行推理。因此能够准确、精准的识别可见的物体及其之间的关系，显得尤为重要，需要保证
图像以高质量水准生成，可见物体不能出现模糊、噪声等情况。
\item 将图像划分为多个区域。CLEVR没有对图像空间进行划分，不便于在空间层面定义一些约束条件，不能
充分考察模型的空间推理能力。通过将图像划分成若干个区域，可以将区域作为逻辑单元，便于定义局部或者跨区域的、全局的约束条件，验证
模型在空间层面上综合运用已有条件，进行逻辑推理的能力。
\end{enumerate}
\subsection{问题层面目标}
问题层面，具体包括以下目标：
\begin{enumerate}[nosep]
\item 以信息缺失物体为核心设计问题。CLEVR中的问题大多围绕图像中的完全可见的物体，即
回答该物体相关的问题的所需信息，全部都包括在图像中。CLEVR中的这一问题，导致CLEVR中缺少信息缺失的情境下的推理。
围绕信息缺失物体设计问题，可以引导模型进行推理、归纳，而非直接对图像进行感知并回答问题，考察模型的逻辑推理能力。
\item 控制问题类型分布。CLEVR中，物体的某些属性的问题的可能答案太少，例如关于材质的问题的可能答案仅有两种，
而颜色与形状的属性可取值较多，对应其相关问题的答案集空间更大，模型通过随机猜测命中的正确答案的概率大大降低。
故要对问题类型进行合理控制，尽可能扩大答案集空间，提高模型在“多值不确定性”下的能力。
\item 覆盖多种推理类型。CLEVR中的很多问题只需一步推理或直接感知，不足以检验神经符号VQA框架在
积木世界多跳推理中的表现。通过在POVQAD中设计不同推理跳数的问题，可以测试模型对链式逻辑的掌握程度。
\end{enumerate}
\subsection{约束层面目标}
约束是对场景中对象空间配置的规则限制，定义对象之间的空间关系或位置要求。
每条约束基于一个约束模板实例化得到，具有明确的逻辑语义。
约束层面，具体包括以下目标：
\begin{enumerate}[nosep]
\item 使用ASP构建背景知识约束。CLEVR中对某个图像而言，缺少对其相关背景知识的设定，
进而无法考察模型是否能真正整合场景逻辑进行思考。而构建规则正是ASP的长处所在。
\item 模版化建模，支持约束组合多样性，形成多样化的环境。
CLEVR中。一方面对图像内物体数量、物体属性取值空间等要素均进行了参数化处理，可以自定义修改，另一方面支持多个模板之间的自由组合。
两种方法搭配，增加了环境的多样性。
\end{enumerate}
\subsection{符号表示层面目标}
符号表示层面的目标为：使用ASP进行统一编码。ASP是神经符号VQA框架的核心所在，在框架内部全程使用ASP进行知识表示，
能够有效减少不同知识表示形式之间进行转换而带来的损耗，保证知识的完整性。
\section{构建准则}
本文旨在构建一个部分可见积木世界场景的空间推理VQA数据集（POVQAD），用以模拟
现实世界中信息缺失的场景，并评估模型的空间推理能力。为实现该目标，本文在POVQAD数据集的构建中
遵循如下准则：
\begin{enumerate}[nosep]
\item 每个场景中有一个目标物体被隐藏，图像和逻辑表示中均不可见。场景指的是图像的ASP表示，其中包含了图像的物体属性及各物体之间的空间位置关系。
隐藏物体的目的是为了实现部分可见性，模拟现实中因遮挡或感知局限导致的信息缺失情境。
\item 每个场景都必须满足由 ASP 定义的一组环境约束，目的是保证场景内部在逻辑层面上的合理性，避免不同约束之间发生冲突。
例如，不能同时出现“区域1中所有物体都是蓝色”和“区域1中没有蓝色的物体”这种自相矛盾的约束。
\item 在环境约束定义、场景生成与问题的形式化表示方面，均采用ASP进行表示。原因在于以下几方面：

ASP支持高层次知识建模。POVQAD所涉及的空间推理任务，本质上是一个多层次的知识表示与约束求解问题。
环境约束定义了某类场景中物体属性分布的全局或局部规则；场景构建要求从这些规则中生成满足逻辑一致性的物体布局；
问题表示与求解则需要基于观察到的部分信息，反推出隐藏物体的属性。
在这些任务中，ASP具有以下核心优势：（1）声明式建模，使用逻辑规则直接描述“应该满足什么”，
而不是“如何计算”，避免编程过程的冗余细节；（2）非单一模型求解，ASP可自动求解所有满足条件的模型，天然适合多解推理任务；
（3）支持不完备信息建模，通过否定与缺省推理机制，可以有效表示部分可见性下的场景；
（4）可组合性强，环境约束、已知信息与问题查询均可通过逻辑程序合并输入，实现统一推理。

在环境约束生成中，ASP能够高效表达复杂的属性限制。环境约束可能包括限制属性取值（如“区域0中所有物体必须是红色或黄色”）、
限制物体数量（如“区域1中恰好有2个小物体”）、跨区域比较（如“区域1和区域2中相同颜色的物体数不能超过3”）以及
排他性限制（如“不得存在两个属性完全一致的物体”）。这些约束结构灵活，复杂度高，传统的数据生成方法难以精确表达。而 ASP 的规则语法（例如 :- 引入约束，\#进行计数等）非常适合表达此类逻辑条件。

在场景构建中，ASP可有效保障逻辑一致性。在场景构建过程中，ASP求解器被用作生成器，即在给定环境约束的前提下，
通过ASP求解器获得符合约束的场景。每个完整场景对应一组ASP事实；ASP求解器在物体属性组合与区域位置上
进行求解；最终仅保留满足所有约束条件的合法解集，用于渲染与问题生成。通过在场景构建中使用ASP求解器，
可以系统性地采样出大规模、逻辑一致、属性多样的积木世界场景，避免人工构造或启发式方法中可能出现的歧义与逻辑错误。

在问题表示中，ASP实现了可求解性与可解释性的统一。POVQAD中的问题不仅以自然语言形式存在，
还被转换为对应的ASP查询规则，这一方案的优势包括：（1）问题可直接嵌入ASP推理流程，与部分场景信息与环境约束统一求解；
（2）保证所有问题均具有可求解性：Clingo 求解器可验证其是否有合法答案；（3）通过分析解集大小、排除路径等，可进行问题难度分级与推理链可视化；
（4）每个问题的“答案空间”明确，适用于多解式评估与开放性回答。例如，问题“What is the color of the object with the same material as the object to the right of the red sphere?”可形式化为：
\begin{lstlisting}
query(Q) :-
    has_property(X, color, Q),
    has_property(X, shape, cylinder),
    has_property(Y, shape, sphere),
    has_property(Y, color, red),
    right(Y, X),
    same_material(X, Y),
    X != Y.
\end{lstlisting}
这种形式使得问题的语义清晰、结构明确，便于执行与验证。
\item 图像中物体属性设置形状、尺寸、材质、颜色四种属性。具体属性值的设置上，尺寸的可能取值为小、中、大，颜色的可能取值为红色、蓝
色、绿色、黄色、灰色、棕色、紫色和青色，材质的可能取值为橡胶和金属，形状的可能取值为圆锥体、球体、圆柱体和立方体。

选取这四种基本属性，是因为它们是物体最直观且容易区分的特征，并且与原始 CLEVR 数据集保持一致，便于进行比较研究。对
每个属性的可能取值进行了限制（例如，八种颜色，四种形状，两种材质，三种尺寸），
这样做的目的是为了简化推理过程并控制答案的搜索空间，避免由于可能的属性组合过多而导致的推理复杂度过高。
\item 图像中对空间进行划分，并分为四个区域，取值分别为0、1、2、3，并同时规定每个物体只能在图像的一个区域中，不能同时跨多个区域。
为图像空间划分区域，主要的优势在于为图像生成和问题生成指定作用范围约束，有利于提升数据集的复杂性和多样性。
\item 问题类型删除了CLEVR中的是否类问题（即比较属性、比较数量和存在性问题）以及计数问题，仅保留属性查询类问题。
做出这一规定的原因在于以下三点：
（1）POVQAD的核心目标是评估模型在部分可见积木世界场景中对目标物体
属性的推理能力，尤其强调在只有一部分信息和环境约束之下，通过排除法找出符合条
件的物体的可能属性值；（2）是非题和计数问题通常返回的是一个布尔值或者整数，不
需要明确识别不可见物体的属性。ASP 求解器在解决此类问题时，整个求解过程往往不
具备复杂的排除性与可解释性；（3）属性查询类问题的问题目标是询问不可见物体的某
个属性是什么，ASP 求解器对该类问题的求解过程可以形成明显的逻辑链条，从部分信
息及环境约束中推导出不可见物体的属性值。

因此，属性查询类问题更加契合“通过环境约束与部分观测信息联合推导目标物体属性”的这一目标，本文在POVQAD中仅保留属性查询类问题。
\end{enumerate}
\section{数据集定义}
基于上述构建目标，本文将POVQAD数据集形式化定义为一个五元组的集合：
$$D = \{ (I_i,P_i,Q_i,\Pi_i ,A_i) | i=1,2,...,N \}$$
其中，每个元素$(I_i,P_i,Q_i,\Pi_i ,A_i)$是数据集中的一个样例，各组成部分定义如下：
\begin{enumerate}[nosep]
\item \textbf{$I_i$}为图像，是通过 Blender 渲染的基于场景生成的 3D 图像。
每张图像表示一个三维积木世界场景，所有可见物体均按预定义属性摆放。每个图像中都刻意隐藏了一个物体，以模拟部分可见条件。
图像示例如图\ref{POVQAD-figure}。
\begin{figure}
\centering
\includegraphics[scale=0.6]{figures/POVQAD中图像示例.png}
\caption{POVQAD中图像示例}
\label{POVQAD-figure}
\end{figure}
\item \textbf{$S_i$}为场景，是对当前图像中所有可见物体的ASP表示，采用ASP进行表示。
其中主要包含以下内容：每个可见物体的属性，包括尺寸、颜色、材质、形状；每个物体所属的区域；可见物体之间的空间关系，如\textbf{left(X,Y)}表示X在Y的左边；
被隐藏的物体（即问题中提及而图像中不存在的物体）不会出现在部分场景信息中。
\item \textbf{$Q_i$}为问题，使用自然语言形式进行表示，例如“What shape is the small red object that is to the left of the yellow cube?”。
所有问题均为属性查询类问题，专门针对物体的四个属性之一：颜色、尺寸、形状或材质。
\item \textbf{$QA_i$}为问题的ASP表示，例如：
\begin{lstlisting}
query(Q) :-
    has_property(X, color, Q),
    has_property(X, shape, cylinder),
    has_property(Y, shape, sphere),
    has_property(Y, color, red),
    left(Y, X),
    same_material(X, Y),
    X != Y.
\end{lstlisting}
\item \textbf{$\Pi_i$}为环境，是当前图像所属环境的一组约束规则，采用ASP进行表示。以下为一组约束示例：
\begin{lstlisting}
% 约束示例
% 区域0中所有物体的形状必须是圆柱体
:- obj(X), at(X, 0), has_property(X, shape, cylinder).
% 区域1中蓝色物体的数量大于2个
:- #count{X: has_property(X, color, blue), at(X, 1)} > 2.
\end{lstlisting}
\item \textbf{$A_i$}为答案集，表示该问题对应的正确答案。
\end{enumerate}
\section{构建流程}
POVQAD的构建流程如图\ref{fig:dataset-generation}所示，共包括5个步骤。各个步骤的功能如下：
\begin{enumerate}[nosep]
\item \textbf{生成环境}：随机选取部分约束模板，并将模板实例化，最终得到环境。
\item \textbf{构建完整场景}：将环境实例化，并将环境输入ASP求解器进行求解，得到对应的完整场景。
\item \textbf{构建部分场景并生成问题}：随机选取完整场景中的某个物体并将其从场景中删除，进而获得部分场景。同时根据问题模板生成关于该物体自然语言问题以及问题的ASP表示。
\item \textbf{答案生成与验证}：将完整场景和问题的ASP表示一起输入ASP求解器，获得问题的答案。
\item \textbf{图像渲染与样例生成}：根据部分场景使用Blender渲染，获得积木世界图像，并将图像与部分场景、问题的ASP表示、问题答案、自然语言问题、环境这六项进行组合，获得一个完整的POVQAD中的样本。
\end{enumerate}
\begin{figure}[h]
\centering
\includegraphics{figures/pipeline-POVQAD.drawio-crop.pdf}
\caption{POVQAD构建流程}
\label{fig:dataset-generation}
\end{figure}

\subsection{生成环境}
在POVQAD中，一个环境包含了一组约束规则，用于限定在该环境下生成的所有场景所必须满足的
属性组合、区域位置的约束条件。环境的作用是，在宏观层面上对后续生成的图像、问题进行把控，
以控制场景复杂度，并保证数据集保持逻辑一致性。在数学上可以如下表示环境：
$$ \varepsilon = \{C_1,C_2, ..., C_k \}, C_i \in ASP \quad Constraint $$
其中，每个$C_i$是用 ASP 表示的一条逻辑约束规则。

环境的生成过程包括以下步骤：（1）预定义11种约束模板；（2）确定模板中的相关参数；（3）确保每个环境中至少包括区域级约束和跨区域约束；（4）对所有生成的约束经语义检查与逻辑一致性
验证。

约束模板是依据常见的逻辑组合来进行设计的，覆盖了取值限定、逻辑否、逻辑或等基本逻辑模式，
部分约束模板的ASP编码表示以及对应表示含义见表\ref{tab:asp_templates}。
\begin{table}[h]
    \centering
    \renewcommand{\arraystretch}{1.0}
    \begin{tabular}{|p{3cm}|p{12cm}|}
        \hline
        \textbf{模板} & \textbf{描述} \\
        \hline
        \textbf{模板1（取值约束）} & 
        \texttt{:- obj(X), at(X, R), not has\_property(X, P1, V1).} \\ 
        & 解释: 对区域R中的所有物体，它们P1属性的取值均为V1。 \\ 
        & 具体实现: :- obj(X), at(X, 0), not has\_property(X, color, red). \\
        \hline
        
        \textbf{模板2（否定约束）} & 
        \texttt{:- obj(X), at(X, R), has\_property(X, P1, V1).} \\ 
        & 解释：对区域R中的所有物体，它们的P1属性的取值，均不能为V1。 \\ 
        & 具体实现：:- obj(X), at(X, 0), has\_property(X, material, metal). \\
        \hline
        
        \textbf{模板3（恰有N个约束）} & 
        \texttt{:- \#count\{X: has\_property(X, P1, V1), obj(X), at(X, R)\} != N.} \\ 
        & \textbf{解释}：在区域R中，恰好有N个物体的P1属性的取值为V1。 \\ 
        & 具体实现：:- \#count\{X: has\_property(X, size, small), obj(X), at(X, R')\} != 2. \\
        \hline
        
        \textbf{模板4（至少有N个约束）} & 
        \texttt{:- \#count\{X1, X2: sameProperty(X1, X2, P1), obj(X1), obj(X2), at(X1, R1), at(X2, R2)\} < N.} \\ 
        & 解释：在区域R1和区域R2中，至少有N对物体，它们的P1属性的取值都是V1。 \\ 
        & 具体实现：:- \#count\{X1, X2: sameProperty(X1, X2, shape), obj(X1), obj(X2), at(X1, 1), at(X2, 2)\} < 1. \\
        \hline
        
        \textbf{模板5（或约束）} & 
        \texttt{:- obj(X), at(X, R), not has\_property(X, P1, V1), not has\_property(X, P1, V2).} \\ 
        & 解释：区域 R中的所有对象都具有属性 P1 的 V1 值或属性 P2 的 V2 值。 \\ 
        & 具体实现：:- obj(X), at(X, 1), not has\_property(X, color, yellow), not has\_property(X, color, blue). \\
        \hline
    \end{tabular}
    \caption{部分约束模板示例}
    \label{tab:asp_templates}
\end{table}

模板实例化生成环境的过程中，需要设定一些参数，具体包括：
\begin{enumerate}[nosep]
\item \textbf{规则模板数量}：每个环境实例化多少条规则模板，规定单个环境最多实例化15条。
\item \textbf{规则类型分布}：哪些类型的模板要被实例化（局部、跨区域或全局）。
\item \textbf{区域范围}：规则作用在哪些区域。根据POVQAD的定义，区域编号为0、1、2、3。
\item \textbf{数量参数}：恰有、至少、至多约束中要求的具体数量。
\end{enumerate}

POVQAD规定每个环境最多由15条约束规则模板实例化构成，这一数值是经过多方面权衡确定的，目的主要在于以下几方面：
\begin{enumerate}[nosep]
\item 逻辑复杂度与可解性的平衡。如果某个环境中的约束规则过少，会导致后续生成的场景过于松散，
物体属性组合高度自由，推理空间过大，导致问题复杂度过大，难以进行有效推理。
如果约束规则过多，则会造成约束之间产生冲突，导致ASP求解器难以知道合法的解，影响求解效率，进而影响场景的生成。
\item 控制生成时间与可维护性。每条规则在 ASP 中都可能极大影响解空间，规则数上升将显著增加 ASP 求解时间。此外，
在大规模数据生成中，15 条以内的环境可以在数秒内稳定求解出场景，利于批量生成和调试。
\end{enumerate}

在生成环境的过程中，规定每个环境中至少包括区域级约束和跨区域约束，共计两种约束。做出这一规定的目的在于
增强环境的逻辑层次性与推理深度，具体原因如下：
\begin{enumerate}[nosep]
\item 支持多层次推理链的构造。区域级约束用于构建局部一致性，跨区域约束用于建模全局对比或协同关系。
同时使用这两类约束，可以使推理问题具有从局部到跨区域的空间层级，增加问题的空间深度。
\item 避免场景构造退化为简单的组合。如果只使用区域级约束，那么后续根据环境生成场景时，将会变成多个局部区域的简单组合，
缺乏各个区域之间的相互关联。添加跨区域约束之后，有助于生成具有全局一致性/相互限制/相互支撑的复杂场景。
\item 支撑部分可见场景下的间接推理。在部分场景中，若不可见物体在区域0中缺失，模型可以通过区域0的其它规则
或者区域0与区域1的对比或者联动规则来进行属性排除或依存判断。而如果采用单一的区域级约束，
那么对于区域0中的物体的问题，模型只能依赖于区域0的局部信息进行推理，缺乏全局视角，不利于考察模型的宏观层面推理能力。
\end{enumerate}

进行语义检查与逻辑一致性验证的具体方案是用ASP求解器（本文中采用Clingo）对生成的约束尝试进行求解，
如果Clingo没有提示错误信息，并且能够成功求解出至少一个合法的解集，则说明该环境的约束规则是逻辑一致的，并且
能够顺利通过语法检查。本步骤的主要目标是避免后续出现死循环、空解等问题。

最终，一共生成了30个环境，数据集中的所有场景均匀分布在这些不同的环境之中。
控制生成30个环境的原因是，这一数量的环境实际上可以供后续生成数百万个不同场景和问题，足够支撑进行大规模训练与严格测试。
环境的具体示例见附录\ref{appendix:environment}。

\subsection{构建完整场景}
在获得特定环境后，使用 ASP 求解器在逻辑层面构建符合这些约束的完整场景。
完整场景是反映了一幅图像中所有物体及物体间空间关系的ASP规则的集合。
为了具体说明两者之间的关系，下面通过一个例子予以说明。在某个场景中，包含以下ASP规则：
\begin{lstlisting}
obj(0). has_property(0, color, red). has_property(0, shape, cube). at(0, 1).
obj(1). has_property(1, color, green). front(1, 0).
\end{lstlisting}
该场景可以通过Blender渲染为图像，该图像中有一个红色立方体出现在区域1中，
同时还有一个绿色的物体出现在该红色立方体的前方。

生成完整场景的步骤如下：
\begin{enumerate}[nosep]
\item 设定环境参数。在生成的环境的基础之上，需要指定一些参数，以控制生成具体的场景，包括物体总数量、
物体区域分配、空间关系配置等等。
\begin{lstlisting}
% 颜色可取值范围是红色、蓝色、绿色、黄色
color(red; blue; green; yellow).
% 物体的形状可取值范围是立方体、圆柱体、球体
shape(cube; cylinder; sphere).
% 物体的材质可取值范围是金属、橡胶
material(metal; rubber).
% 物体的尺寸可取值范围是小、大
size(small; large).

obj(0..5). % 生成编号为0到5的物体，总共6个物体。要生成其它数量的物体，只需要修改这里的数字即可。
\end{lstlisting}
\item 编写ASP生成规则。为了给每个物体生成属性，需要编写ASP规则来让ASP求解器为物体分配属性。
\begin{lstlisting}
1 { has_property(X, color, C) : color(C) } 1 :- obj(X).
1 { has_property(X, shape, S) : shape(S) } 1 :- obj(X).
1 { has_property(X, size, Z)  : size(Z)  } 1 :- obj(X).
1 { has_property(X, material, M) : material(M) } 1 :- obj(X).

1 { at(X, 0..3) } 1 :- obj(X).  % 每个物体只能在一个区域中
\end{lstlisting}
通过ASP中的选择规则（choice rules），要求ASP求解器从可能的值中选择一个赋给物体的属性。
\item ASP求解器生成解集。
使用 Clingo 等 ASP 求解器，将“环境 + 属性范围 + 生成规则”作为输入，ASP求解器会搜索满足所有约束的解空间，并输出一组满足条件的回答集。
以下是一个可能的解集示例，构成了一个完整场景。其中涉及到的谓词的功能如下：谓词\texttt{obj}用于定义不同的物体（所有物体的名称用0，1等数字来表示）。
谓词\texttt{has\_property(obj, Attribute, Value)}用于将对象的名为Attribute的属性的值设置为Value。
对象之间的空间关系用谓词\texttt{left}、\texttt{right}、\texttt{front}、\texttt{behind}来表示，例如
\texttt{left(A, B)}表示B位于A的左侧。
\begin{lstlisting}
%场景中的物体
obj(0). obj(1). obj(2). obj(3).

%物体的属性
at(0, 2).
has_property(0, color, green).
has_property(0, size, large).
has_property(0, material, rubber).
has_property(0, shape, cylinder).
....

%物体间的空间关系
front(1, 0). right(1, 0). ...
\end{lstlisting}
\item 验证与采样。在通常情况下，ASP求解器会为每个环境会生成成千上万条符合条件的回答集。本文采取随机采样
的策略以选取场景，目的在于以下几点：（1）控制数据集的规模。每个场景后续要生成图像、问题、ASP表示、答案，
如果不采样，那么数据规模会指数增长，造成资源浪费，并且生成的场景也需要人工审核，如果场景规模过大，
将会很难进行有效的审核；（2）确保样本的多样性。ASP求解器会返回多个合法的回答集，但无法保证这些回答集在属性组合上的多样性，
如果不随机采样，而是直接选取前若干条或者后若干条，会导致模式重复。而采用随机采样的方法，可以打乱解集的顺序，
提升物体数量、属性组合分布、不同空间关系分布和场景在视觉方面的多样性；（3）避免偏差性解集。
在解集空间中，某些满足约束的组合可能更“常见”或“易于求解”，如果直接按顺序采样，会让这些组合比例过高。
随机采样有助于防止数据偏态分布，使模型不会过拟合于高频属性组合。

具体而言，本文使用Python的\texttt{random.shuffle()}将解集进行随机打乱。此后，从每个环境生成的所有场景中，
采样100个场景。在采样完成之后，通过人工检查，确保场景的区域覆盖均衡、属性组合多样并且没有出现重复物体的情况。
\end{enumerate}
\subsection{构建部分场景并生成问题}
本环节的目标是，从完整场景中随机选择一个物体作为被隐藏的目标物体，并围绕该物体构造相关问题，并同时使用自然语言及ASP对问题进行表示。
整个环节的流程图如\ref{generate-partial-scenes-and-questions}所示。
\begin{figure}[h]
\centering
\includegraphics[scale=0.6]{figures/部分场景及问题生成-crop.pdf}
\caption{构建部分场景并生成问题流程图}
\label{generate-partial-scenes-and-questions}
\end{figure}

选择目标物体的过程需要满足以下条件：
\begin{enumerate}[nosep]
\item 从完整场景的所有物体中随机选取一个，在随机选取的过程中，要注意保持均衡，不能
一直选取单一区域的物体或者相同属性的物体，以免造成数据偏态分布。
\item 被选择物体不能是唯一出现某一属性的对象，避免由于移除该物体后，
导致场景中该属性的值无法被推断，导致问题无解。
\item 该物体将在后续问题中作为查询目标。
\end{enumerate}

选择$Obj_i$后，需要将完整场景中关于$Obj_i$的所有事实全部移除，生成部分场景。具体需要做到以下几点：
\begin{enumerate}[nosep]
\item 删除\texttt{obj(i)}、\texttt{at(i, R)}、\texttt{has\_property(i, P, V)}；
\item 删除所有涉及$Obj_i$的空间关系谓词，如\texttt{left(i, j)}、\texttt{right(i, j)}等；
\item 保留其余物体的信息与关系。
\end{enumerate}
从而得到一个只包含可见物体的子结构，记为 $Partial_i$，该场景中缺少了目标物体的显式信息。

随后，将根据$Obj_i$的属性来生成相关问题。
每一个生成的问题，应该满足如下条件：（1）针对被隐藏对象的某一属性；
（2）基于剩余可见物体和环境约束进行间接推理；（3）问题语义必须明确且答案集非空。
以某个问题的生成为例，$Obj_i$的属性包括：尺寸为小、材质为金属、颜色为灰色、形状为立方体
，那么可以随机选取形状作为被查询属性，并将“尺寸为小”作为已知信息放置在问题当中。
为了便于控制问题类型的数量分布，本文规定每个问题只能查询上述四个属性中的一个，而不同时查询多个属性。
与此同时，问题生成器也将从图中选取一个
参照物体，用以共同组成问题。考虑到不同种类属性的可能取值数量不同，进而不同属性的问题的可能答案数量也不同，
本文据此规定每种属性的问题在数据集中所占的比例：颜色与形状各占40\%，材质与尺寸各占10\%。
该比例同样通过ASP约束来进行实现。
需要注意生成的问题仅为属性查询问题，不包括是非题和计数题等其它CLEVR中原有的问题类型，理由在3.1节构建目标中已有陈述，此处不再赘述。

POVQAD采用问题模板来构造自然语言问题，
一种供参考的模板如\ref{asp:question-template}中所示，
其中<Z2>、<C2>、<M2> 表示待查询对象的已知属性（例如尺寸、颜色、材质），由随机策略从完整场景中选取；
<R> 为空间关系（如left、right、front、behind），其取值既满足随机性，又依赖于完整场景中物体间的真实空间分布；
<Z>、<C>、<M>、<S> 则代表参考对象的属性。这种模板化设计不仅使自然语言问题的结构化描述成为可能，
而且便于后续转换为ASP的形式化表示，从而实现问题求解的自动化。
\begin{lstlisting}[label=asp:question-template]
What shape is the < Z2 > (size) < C2 > (color) < M2 > (material) [that is] 
< R > (relation) the < Z > (size) < C > (color) < M > (material) < S > (shape) ?
\end{lstlisting}

模板实例化之后，得到的自然语言问题可能为：\texttt{What shape is the small red rubber object that is left of the large green metal cube?}。
获得自然语言问题之后，再使用ASP对其进行表示。对每一个自然语言问题，都是从一个问题模板出发，填充占位符，
然后生成的。所以，自然语言和ASP查询具有一一对应的逻辑结构，可以实现自动转换。
对上述获得的自然语言问题，解析占位符，可以得到：
\begin{enumerate}[nosep]
\item 被查询对象：size（small）、color（red）、material（rubber）
\item 参考对象：size（large）、color（green）、shape（cube）
\item 空间关系：left(X, Y)
\item 查询属性：shape
\end{enumerate}

随后自动生成ASP查询规则如下所示，其中X是隐藏对象，Y是参考对象，Q是要查询的属性值，has\_property是表示属性的谓词。
\begin{lstlisting}
query(Q) :-
    has_property(X, shape, Q),
    has_property(X, size, small),
    has_property(X, color, red),
    has_property(X, material, rubber),
    has_property(Y, size, large),
    has_property(Y, color, green),
    has_property(Y, shape, cube),
    left(X, Y),
    X != Y.
\end{lstlisting}
\subsection{答案生成与验证}
答案生成与验证环节的核心任务是：
将问题的ASP表示$QA_i$、部分场景$P_i$与环境约束$\Pi_i$被统一输入给Clingo进行求解，尝试生成答案集$A_i$，并检验
生成的答案是否有效。
具体步骤如下：

首先，将问题$QA_i$、部分场景$P_i$与环境约束$\Pi_i$，这三部分拼接到同一个\texttt{.lp}文件中，
例如：
\begin{lstlisting}
% 1. 场景信息
obj(0). obj(1).
has_property(0, color, green).
...

% 2. 环境约束
:- obj(X), at(X, 0), not has_property(X, shape, cube).
...

% 3. 问题
query(Q) :- has_property(X, color, Q), ..., same_material(X, Y).
\end{lstlisting}

此后，调用Clingo开始进行求解，并从Clingo的输出结果中提取\texttt{query(Q)}的值集合，例如：
\begin{lstlisting}
query(red) query(green) % 说明 red, green 是该问题的所有可能答案值。
\end{lstlisting}

答案集$A_i$生成之后，为了保证问题的质量和有效性，本文对生成的答案集采取了一些筛选措施：（1）答案非空。答案集必须满足$|A_i| \geq 1$
，否则表示该问题无解，需要被排除；（2）答案不全。如果答案集等于该属性所有可能取值（例如颜色有8个取值，结果为8个值），说明该问题逻辑约束不足，属于信息缺失型问题，也将被剔除。
因此筛选条件为：
$$1 \leq |A_i| < |\mathcal{A} |$$
其中$\mathcal{A} $是该查询属性的所有取值集合。

最终，答案被编码为一个取值集合，例如某个查询颜色的问题的答案集为\{ red \}，某个查询形状的问题的答案集为
\{ cube, sphere \}。
\subsection{图像渲染与样例生成}
图像渲染与样例生成的目的是将场景转换为3D图像，以提供用于VQA任务的真实图像输入，并将图像与问题、
答案集进行统一组织，形成可供模型训练和推理的完整样例。本文使用Blender进行图像生成，具体流程如下：
\begin{enumerate}[nosep]
\item 初始化场景。在这一步中，会设置Blender的一系列渲染参数，包括图像宽度、图像高度、渲染引擎、分辨率百分比等等，以及
配置GPU渲染。
\item 添加对象。将对象添加到场景中，并设置材质、颜色、形状等属性以及所在区域。
\item 检查对象可见性。在渲染之前，需要确保所有对象在图像中可见。具体实现方法是，检查每个对象的像素数量，判断是否满足最低要求，低于最低要求则视为该对象不可见。最低像素数的默认值设置为200，
因为生成的图像的默认分辨率为320x320，200个像素大约占据了图像的0.2\%。这一比例在视觉上足够明显，同时
不会因为分辨率限制而导致过多的场景被丢弃。
\item 执行渲染。渲染当前场景，并将文件保存到指定目录。如果在渲染过程中发生异常，将会进行最多三次的重试。
\item 删除对象。将目标物体从场景中删除，得到最终的图像。
\end{enumerate}

在图像生成完成之后，每一条数据样例$D_i$会被组织为一个JSON对象。JSON对象的结构如下：
\begin{lstlisting}
{
    "question_nl": "What color is the small rubber object to the left of the red cube?",
    "image": "partial_scene_0001.png",
    "answer": ["red", "green"],
    "environment": "环境约束具体内容",
    "scene_asp": "场景的ASP表示",
    "question_asp": "query(Q) :- has_property(X, color, Q), ...",
}
\end{lstlisting}

最后，所有的数据样例的JSON对象会被统一存储在一个JSON文件中。
\section{数据集质量评估}
为验证构造的POVQAD数据集的可靠性与研究价值，本节从POVQAD的可执行性与一致性、统计分析方面进行研究。
\subsection{可执行性与一致性评估}
可执行性指的是POVQAD中每个样例的ASP程序能够经Clingo求解器执行，不出现语法错误。
一致性指的是对POVQAD中每个样例的ASP程序，Clingo对其的求解结果与样例中给出的标准答案一致。

本文对POVQAD中所有ASP程序依次使用Clingo进行执行，统计语法错误率，结果为0.2\%，
并且对能够正确执行的ASP程序的运行结果与标准答案进行对比分析，一致率为99.5\%，以上两点证明本文生成的ASP程序质量较高，
使用ASP构造POVQAD的方法合理。
\subsection{统计分析}
POVQAD中问题分布的统计图见图\ref{fig:question_statistics}。从图\ref{fig:question_statistics}（a）中可得知，有关颜色和形状的问题在POVQAD数据集中
占比最高，分别是39\%和37.6\%，关于大小和材质的问题则相对较少，分别只占到了13.6\%和9.8\%。
所提问题的类型取决于被查询的物体的属性，在生成数据集的过程中，允许用户设置问题类型的预期占比。
以上统计得到的POVQAD中问题类型占比，是基于以下的设置生成的：颜色问题占比40\%，形状问题占比40\%，大小问题占比10\%，材质问题占比10\%。
做出如上设置的原因是，与材质（只有两个值）相比，颜色和形状等属性包含更大的值集合（颜色有 8 个值，形状有 4 个值），
则对颜色和形状提问的问题有更多的潜在答案，故应将颜色和形状的相关问题的占比调高，以充分展示相关问题的答案集空间。

图\ref{fig:question_statistics}（b）、（c）、（d）和（e）分别说明了各种问题类型（尺寸、形状、材质和颜色）的潜在答案的分布。
生成数据集的目标之一是实现均衡的分布，避免大多数问题都导致相同的答案集的情况。
例如，当问题涉及物体的大小时，其可能的解可以是
 \{大, 中\}、\{大, 小\}、\{小, 中\}、\{大\}、\{中\} 或 \{小\} 之一，
 如图\ref{fig:question_statistics}（b）所示。由于查询属性为颜色的问题的可能答案数量很大（因为颜色可以取 8 个值），
 因此图\ref{fig:question_statistics}（e）中并未列出整个空间。根据统计图可以看出，在生成过程中没有偏向任何特定的答案。
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/question_distribution-crop.pdf}
    \caption{问题分布统计}
    \label{fig:question_statistics}
\end{figure}

图\ref{fig:template_statistics}（a）中展示了POVQAD中问题在不同问题模板上的分布情况，\ref{fig:template_statistics}(b)中展示
了特定类型问题根据场景中物体数量划分的分布情况。
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.45]{figures/question_template_distribution-crop.pdf}
    \caption{问题模板分布情况}
    \label{fig:template_statistics}
\end{figure}
\section{数据集构建工具}
本节从工程角度介绍为构造POVQAD而专门开发的构建工具POVQAD-Builder，该工具旨在以程序化的方式生成包含多个具有不同属性（如形状、颜色、大小、材质）物体的三维场景图像，
并自动为其配对相应的需要空间推理才能回答的问题。POVQAD-Builder主要包含两个核心模块：图像生成模块和问题生成模块。
\subsection{图像生成模块}
图像生成模块使用Blender作为底层渲染引擎，并通过Python脚本进行自动化控制。其主要流程如下：
\begin{enumerate}[nosep]
\item \textbf{场景参数定义}：在元数据文件metadata.json中定义场景中可能出现物体的属性范围，包括可选的形状（例如，立方体、球体、圆柱体）、颜色（例如，红色、蓝色、绿色）、材质（例如，金属、橡胶）和大小（例如，小、大）。
\item \textbf{场景实例化}：对于每个需要生成的图像，脚本在Blender环境中创建一个空场景。随后，根据预设的参数（例如，场景中的物体数量范围），随机选择指定数量的物体。
\item \textbf{物体属性分配与放置}：为每个选定的物体随机分配在metadata.json中定义的形状、颜色、材质和大小属性。脚本接着将这些物体随机放置在预定义的场景空间内，同时确保物体之间不会发生过度重叠，并且所有物体都位于摄像机的视野内。
\item \textbf{渲染设置}：配置场景的光照条件（如光源类型、位置和强度）和摄像机参数（如位置、朝向、焦距）。
\item \textbf{图像渲染与场景信息输出}：调用Blender的渲染引擎生成最终的图像文件，以PNG格式保存。与此同时，脚本还会生成一个结构化的场景图文件，以JSON格式保存。该文件详细记录了场景中每个物体的精确属性（形状、颜色、材质、大小）及其三维空间坐标和相互关系。该场景文件是后续问题生成的核心输入。
\end{enumerate}
\subsection{问题生成模块}
问题生成模块以上一步输出的结构化场景文件为输入，旨在生成与对应图像内容相关的、多样化的自然语言问题及其答案。其工作流程概括如下：
\begin{enumerate}[nosep]
\item \textbf{场景解析}：脚本首先加载并解析场景文件，提取其中包含的所有物体及其属性和空间关系信息。
\item \textbf{问题模板与程序化生成}：该模块采用基于模板的方法生成问题。根据先前预定义的一系列问题模板进行生成，这些模板覆盖不同类型的推理任务
\item \textbf{模板实例化与答案生成}：Python脚本遍历场景图中的物体和关系，尝试用具体的物体和属性实例化这些模板。对于每个成功实例化的问题，脚本会再次查询场景图以确定准确的答案。
\item \textbf{输出}：输出一个包含问题列表的文件，以JSON格式保存。每个条目包含生成的自然语言问题、对应图像的文件名、问题的ASP表示、以及标准答案。
\end{enumerate}
\section{本章小结}
本章聚焦CLEVR数据集的场景完全可见、不要求模型使用外部背景知识进行推理等方面的缺陷，构建一个新的数据集POVQAD，以满足
本文对部分可见积木世界场景下空间推理问答的研究需要。在结构上，本章按照构建目标、构建原则、构建流程、统计与和理性分析依次展开。

3.1节介绍了POVQAD的构建目标，并在图像、问题、约束和符号表示层面进行了具体阐释。

3.2节介绍了POVQAD的构建准则，包括图像中的物体属性、问题类型等方面的准则，
并对每条准则介绍了具体要求以及理由。

3.3节介绍了POVQAD的定义，包括数据集中每个样本中所包含的数据项的定义。

3.4节介绍了POVQAD的构建流程，从生成环境、构建完整场景、构建部分场景并生成问题、答案生成与验证、图像渲染与样例
生成共五个方面对POVQAD的构建展开详细论述。

3.5节介绍了POVQAD的质量评估，从可行性与一致性评估和统计分析上对POVQAD的可用性进行了评估。

3.6节介绍了POVQAD的构建工具POVQAD-Builder，介绍了其图像生成模块和问题生成模块的工作流程。

本章为后续神经符号VQA框架在部分可见积木世界场景下的空间推理问答的实验与分析奠定了坚实的数据基础。