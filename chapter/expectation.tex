\chapter{结论与展望}
\section{本文工作总结}
本文的主要工作如下：
\begin{enumerate}[itemsep=0pt,parsep=0pt]
\item 构建了一个旨在考察模型在回答部分可见场景的空间推理问题方面的能力的数据集。在 CLEVR 数据集的基础上，本文构建了 POVQAD 数据集，并对其进行了统计分析和质量检验，确保数据集中各类问题分布均匀。
\item 设计了一种面向空间推理领域的神经符号框架。该框架包含视觉场景理解、语义解析、迭代反馈与规则修正、
规则蒸馏、ASP推理等模块，并通过对比实验验证该框架在不同 LLM 上均能提升系统在部分可见场景中的空间推理能力，具有良好的泛化性能。
\item 设计实现了一个用于自动规划的课程教学演示的问答原型系统。该原型系统以本文设计的面向空间推理领域的神经符号框架为核心，采用微服务设计理念拆分各模块，并通过 Redis 缓存等手段对系统进行优化，以尽可能缩短响应时间，满足课堂现场演示的快速响应要求。
最终通过压力测试等技术手段，验证了该原型系统能够承受预想的课堂场景下的用户体量和并发请求量，符合设计预期。
\end{enumerate}
\section{未来工作展望}
本文所设计的面向空间推理的神经符号框架在视觉问答系统中对增强其空间推理能力起到了积极作用，但仍有许多方面有待完善。未来的工作可以从以下几个方面展开。

迭代反馈机制的改进。目前，迭代反馈机制采用的方案是最多三轮迭代。如果在三轮迭代中，
某一轮生成的 ASP 程序能够顺利被 Clingo 执行（即不再出现语法、基础化或推理错误），
则认为程序已经达到预期的正确性，此时可以提前停止迭代。这一方案在一定程度上实现了自适应性，实现了
效率和效果之间的平衡，然而仍有进步的空间。未来可从以下几个方面进行改进：
\begin{enumerate}[itemsep=0pt,parsep=0pt]
    \item 利用元学习或者贝叶斯优化的方法，自动搜索最优的迭代次数和反馈策略。
通过在不同任务或数据集上的交叉验证，可以自适应地调整迭代策略，使其在不同场景下达到最佳表现。
    \item 采用强化学习的方法，训练一个Agent，使其会根据当前生成 ASP 程序的状态和错误信息动态决定是否继续迭代。
类似于LLM-ARC中自动反馈调整的思路，Agent可以通过奖励信号来学习何时停止迭代，以达到最佳的平衡效果\cite{kalyanpur2024llmarcenhancingllmsautomated}。
\end{enumerate}

对数据集的改进。本文构造的POVQAD数据集中，为了简化对相关问题的研究，采用 Blender 引擎渲染静态 3D 几何图像。然而目前应用领域对多模态模型的要求越来越高，静态图像为主的VQA数据集显然并不能
充分考察模型对动态空间变化的推理能力。此外，本文构造的POVQAD数据集，图像的内容是相对较为简单的几何图形，
通过脚本进行生成而得，难以模拟真实物理世界中的物体运动与视角变化等动态场景。尤其是当前智能机器人领域发展
加快，对智能体的要求越来越高，智能体需要实时理解自身运动与物体位置的关系（如“转弯后如何避开障碍物”），而静态问答无法满足需求。
可以考虑的改进方向大致有以下几点：
\begin{enumerate}[itemsep=0pt,parsep=0pt]
    \item 生成动态空间问题。通过Unity或者Unreal等物理引擎的精确控制和程序化生成策略，在合成场景中模拟动态交互，自动生成涉及运动、视角变化和因果推理的动态空间问题。
    \item 增加人类视角问题。本文的POVQAD数据集中的问题，均为相机视角下的问题。可以在生成问题时，
增加更多VQA系统在图像中的人类视角的问题，以考察VQA系统在视角适应上的能力。
\end{enumerate}