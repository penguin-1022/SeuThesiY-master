\chapter{结论与展望}
\section{本文工作总结}
本文的主要工作如下：
\begin{enumerate}[nosep]
\item 构建了一个部分可见积木世界场景空间推理VQA数据集POVQAD。
在 CLEVR 数据集的基础上，本文针对CLEVR数据集场景完全可见、不要求模型使用外部背景知识进行推理等方面的不足，
构建了 POVQAD 数据集，并对其进行了质量评估，证明了POVQAD的可用性。
\item 设计了一种规则自动补充的神经符号VQA框架RCNSP。该框架包含视觉场景理解、语义解析、规则修正、
规则蒸馏、ASP推理、求解结果翻译等模块，借鉴现有神经符号VQA框架的工作，对LLM进行提示词优化以提高ASP规则生成、规则修正的语法及语义准确率，
并新增规则蒸馏模块以实现ASP规则自动拓展。
实验表明，在DeepSeek、LLaMA3、ChatGPT-4o三种LLM上，使用RCNSP比直接向VLM提问的准确率平均提升16.5\%，
比现有的神经符号VQA框架的准确率平均提升8.9\%，表明通过规则蒸馏能有效提升神经符号方法在部分可见积木世界场景中
对空间推理问答的准确率以及RCNSP在不同LLM上的泛化能力。
\item 设计实现了一个积木世界VQA系统。在RCNSP框架和POVQAD数据集基础上，设计实现了积木世界VQA原型系统，
该系统模拟了在自动规划课程的授课场景下，由教师向系统提出积木世界的空间推理问题，系统进行解答并展示推理的中间步骤和逻辑链条，
并支持自定义生成复杂度不同的演示数据集，
为教师向学生展示智能体如何理解外部环境信息并进行规划提供了便利。
初步测试表明该系统在CPU为Intel Core i9-12900K，内存128G，显卡为3张RTX 3090并联的硬件环境下，并发量为38，
90\%响应时间为6.9秒，能够满足自动规划课堂教学场景下的用户需要。
\end{enumerate}
\section{未来工作展望}
本文所设计的RCNSP框架在支持神经符号框架的规则自动拓展、提升神经符号方法在部分可见积木世界场景下的空间推理问答准确率
方面起到了积极作用，但仍有许多方面有待完善。未来的工作可以从以下几个方面展开。

首先是迭代反馈机制的改进。目前，迭代反馈机制采用的方案是最多三轮迭代。如果在三轮迭代中，
某一轮生成的 ASP 程序能够顺利被 Clingo 执行（即不再出现语法、基础化或推理错误），
则认为程序已经达到预期的正确性，此时可以提前停止迭代。这一方案在一定程度上实现了自适应性，实现了
效率和效果之间的平衡，然而仍有进步的空间。可从以下几个方面针对该问题进行进一步研究：
\begin{enumerate}[nosep]
    \item 利用元学习或者贝叶斯优化的方法，自动搜索最优的迭代次数和反馈策略。
通过在不同任务或数据集上的交叉验证，可以自适应地调整迭代策略，使其在不同场景下达到最佳表现。
    \item 采用强化学习的方法，训练一个Agent，使其会根据当前生成 ASP 程序的状态和错误信息动态决定是否继续迭代。
类似于LLM-ARC中自动反馈调整的思路，Agent可以通过奖励信号来学习何时停止迭代，以达到最佳的平衡效果\cite{kalyanpur2024llmarcenhancingllmsautomated}。
\end{enumerate}

其次是对数据集的改进。本文构造的POVQAD数据集中，为了简化对相关问题的研究，采用 Blender 引擎渲染静态 3D 几何图像。然而目前应用领域对多模态模型的要求越来越高，静态图像为主的VQA数据集显然并不能
充分考察模型对动态空间变化的推理能力。此外，本文构造的POVQAD数据集，图像的内容是相对较为简单的几何图形，
通过脚本进行生成而得，难以模拟真实物理世界中的物体运动与视角变化等动态场景。尤其是当前智能机器人领域发展
加快，对智能体的要求越来越高，智能体需要实时理解自身运动与物体位置的关系（如“转弯后如何避开障碍物”），而静态问答无法满足需求。
可以考虑的改进方向大致有以下几点：
\begin{enumerate}[nosep]
    \item 生成动态空间问题。通过Unity或者Unreal等物理引擎的精确控制和程序化生成策略，在合成场景中模拟动态交互，自动生成涉及运动、视角变化和因果推理的动态空间问题。
    \item 增加人类视角问题。本文的POVQAD数据集中的问题，均为相机视角下的问题。可以在生成问题时，
增加更多VQA系统在图像中的人类视角的问题，以考察VQA系统在视角适应上的能力。
\end{enumerate}